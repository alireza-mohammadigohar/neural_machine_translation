{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در این فایل شبکه مولد خصمانه مورد نظر را پیاده سازی میکنیم. این بخش شبکه های تمییزدهنده و مولد را تشکیل داده و از مقادیر وزنهای پیش آموزش دیده در مراحل قبل برای شبکه استفاده می نماید."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9503b6e9c306>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mchainer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutilities\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnmt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttentionalNMT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chainer'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from chainer import *\n",
    "from utilities import *\n",
    "from nmt import Encoder, Decoder, AttentionalNMT\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این کلاس به تعریف شبکه تمییز دهنده می پردازد. یک شبکه عمیق ال اس تی ام یک لایه تعریف می شود. مقادیر اولیه پارامترها نیز از فایل اطلاعات برنامه خوانده می شود "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Discriminator(Chain):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, embed_size, hidden_size, use_dropout, dropout_rate, library):\n",
    "    super(Discriminator, self).__init__(\n",
    "        source_lstm_forward = links.LSTM(embed_size, hidden_size),\n",
    "        source_lstm_backward = links.LSTM(embed_size, hidden_size),\n",
    "        target_lstm_forward = links.LSTM(embed_size, hidden_size),\n",
    "        target_lstm_backward = links.LSTM(embed_size, hidden_size),\n",
    "        final_link = links.Linear(4 * hidden_size, 1),\n",
    "    )\n",
    "    self.embed_size = embed_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.use_dropout = use_dropout\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.library = library\n",
    "\n",
    "Discriminator.__init__ = __init__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این تابع شبکه را با استفاده از بردارهای جاسازی ورودی، خروجی و پیش بینی آموزش می دهد. وضعیت های مخفی این سه حالت در گام های پیشرو و عقب گرد با استفاده از هر بخش از داده های ورودی آموزش داده می شود. این تابع معماری شبکه تمییز دهنده را لایه به لایه مشخص می نماید. در نهایت مقدار خطای شبکه تمییز دهنده و شبکه مولد با استفاده از روش سیگموید آنتروپی محاسبه می شود  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __call__(self, source_embed, target_embed, predict_embed):\n",
    "    source_hidden_states = list()\n",
    "    source_hidden_backward_states = list()\n",
    "    target_hidden_states = list()\n",
    "    target_hidden_backward_states = list()\n",
    "    predict_hidden_states = list()\n",
    "    predict_hidden_backward_states = list()\n",
    "    self.source_lstm_forward.reset_state()\n",
    "    self.source_lstm_backward.reset_state()\n",
    "    for embed in source_embed[::-1]:\n",
    "        source_hidden_backward_states.insert(0, functions.dropout(functions.tanh(self.source_lstm_backward(embed)), ratio = self.dropout_rate))\n",
    "    for embed, hidden_backward in zip(source_embed, source_hidden_backward_states):\n",
    "        concat = functions.concat((functions.dropout(functions.tanh(self.source_lstm_forward(embed)), ratio = self.dropout_rate), hidden_backward))\n",
    "        source_hidden_states.append(concat)\n",
    "    self.target_lstm_forward.reset_state()\n",
    "    self.target_lstm_backward.reset_state()\n",
    "    for embed in target_embed[::-1]:\n",
    "        target_hidden_backward_states.insert(0, functions.dropout(functions.tanh(self.target_lstm_backward(embed)), ratio = self.dropout_rate))\n",
    "    for embed, hidden_backward in zip(target_embed, target_hidden_backward_states):\n",
    "        concat = functions.concat((functions.dropout(functions.tanh(self.target_lstm_forward(embed)), ratio = self.dropout_rate), hidden_backward))\n",
    "        target_hidden_states.append(concat)\n",
    "    self.target_lstm_forward.reset_state()\n",
    "    self.target_lstm_backward.reset_state()\n",
    "    for embed in predict_embed[::-1]:\n",
    "        predict_hidden_backward_states.insert(0, functions.dropout(functions.tanh(self.target_lstm_backward(embed)), ratio = self.dropout_rate))\n",
    "    for embed, hidden_backward in zip(predict_embed, predict_hidden_backward_states):\n",
    "        concat = functions.concat((functions.dropout(functions.tanh(self.target_lstm_forward(embed)), ratio = self.dropout_rate), hidden_backward))\n",
    "        predict_hidden_states.append(concat)\n",
    "    source_average = functions.average(functions.dstack(source_hidden_states), axis = 2)\n",
    "    target_average = functions.average(functions.dstack(target_hidden_states), axis = 2)\n",
    "    predict_average = functions.average(functions.dstack(predict_hidden_states), axis = 2)\n",
    "\n",
    "    predicts_true = self.forward(source_average, target_average)\n",
    "    predicts_generate = self.forward(source_average, predict_average)\n",
    "\n",
    "    loss_discriminator = functions.sigmoid_cross_entropy(predicts_true, Variable(self.library.ones(predicts_true.shape, dtype=self.library.int32)))\n",
    "    loss_generator = functions.sigmoid_cross_entropy(predicts_generate, Variable(self.library.ones(predicts_generate.shape, dtype=self.library.int32)))\n",
    "    loss_discriminator += functions.sigmoid_cross_entropy(predicts_generate, Variable(self.library.zeros(predicts_generate.shape, dtype=self.library.int32)))\n",
    "\n",
    "    return loss_generator, loss_discriminator, functions.sigmoid(predicts_true), functions.sigmoid(predicts_generate)\n",
    "\n",
    "Discriminator.__call__ = __call__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع زیر نیز بخش پیشرو شبکه تمییز دهنده را نشانه می دهد"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(self, source, target):\n",
    "    return functions.reshape(self.final_link(functions.concat((source, target))), (source.shape[0],))\n",
    "\n",
    "Discriminator.forward = forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در کلاس زیر شبکه مولد خصمانه مسئله ماشین ترجمه عصبی را تعریف می نماییم. شبکه ورودی های لازم را در تابع زیر فراخوانی می کند و دو بخش مولد و بخش تمییز دهنده شبکه نیز تعریف می گردد. در صورتی که قبلا شبکه مولد را با استفاده از مدل ماشین ترجمه عصبی پیش آموزش داده باشیم از آن استفاده می نماییم."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CSGANNMT(Chain):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, source_vocabulary_size, target_vocabulary_size, embed_size, hidden_size, source_vocabulary, target_vocabulary, source_word2vec, target_word2vec, use_dropout, dropout_rate, generation_limit, use_beamsearch, beam_size, library, pre_nmt):\n",
    "    super(CSGANNMT, self).__init__(\n",
    "        generator = AttentionalNMT(source_vocabulary_size, target_vocabulary_size, embed_size, hidden_size, source_vocabulary, target_vocabulary, source_word2vec, target_word2vec, use_dropout, dropout_rate, generation_limit, use_beamsearch, beam_size, library),\n",
    "        discriminator = Discriminator(embed_size, hidden_size, use_dropout, dropout_rate, library),\n",
    "    )\n",
    "    if pre_nmt is not None:\n",
    "        copy_model(pre_nmt, self.generator)\n",
    "\n",
    "CSGANNMT.__init__ = __init__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "تابع زیر با استفاده از تکه هایی از داده ورودی، خروجی و هدف اقدام به استخراج استیت های ورودی، خروجی و هدف می نماید. در نهایت با فراخوانی بخش تمییز دهنده مقدار خطای شبکه تمییز دهنده و مولد محاسبه می شود. در این گام مقدار خطای شبکه مولد که در هنگام اجرای خود شبکه عصبی آن صورت می گیرد و همچنین خروجی این شبکه خالی برگردانده می شود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __call__(self, batch_source, batch_target, batch_output):\n",
    "    self.reset_states()\n",
    "    if batch_target is not None:\n",
    "        source_embed_states = list()\n",
    "        target_embed_states = list()\n",
    "        predict_embed_states = list()\n",
    "        for word in batch_source:\n",
    "            source_embed_states.append(functions.tanh(self.generator.encoder.word2embed(word)))\n",
    "        for word in batch_target:\n",
    "            target_embed_states.append(functions.tanh(self.generator.decoder.word2embed(word)))\n",
    "        for word in batch_output:\n",
    "            predict_embed_states.append(functions.tanh(self.generator.decoder.word2embed(word)))\n",
    "        loss_generator2, loss_discriminator, predicts_discriminator_true, predicts_discriminator_generate = self.discriminator(source_embed_states, target_embed_states, predict_embed_states)\n",
    "        loss_generator = None\n",
    "        predicts_generator = None\n",
    "    else:\n",
    "        loss_generator = None\n",
    "        loss_discriminator = None\n",
    "        predicts_discriminator_true = None\n",
    "        predicts_discriminator_generate = None\n",
    "    return loss_generator, loss_discriminator, predicts_generator, predicts_discriminator_true, predicts_discriminator_generate\n",
    "\n",
    "CSGANNMT.__call__ = __call__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "دو تابع زیر یکی استیت های شبکه مولد را ریست می کند و تابع دیگر نیز اقدام به استخراج بردار جاسازی برای کلمات ورودی و هدف می نماید که مقادیر آن بر اساس شبکه مولد محاسبه می گردد. در نهایت نیز مقدار امتیاز تابع تمییز دهنده به عنوان خروجی شبکه بازگردانده می شود"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_states(self):\n",
    "    self.generator.reset_states()\n",
    "\n",
    "CSGANNMT.reset_status = reset_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_score(self, source, target):\n",
    "    source_embed = list()\n",
    "    target_embed = list()\n",
    "    for word in source:\n",
    "        source_embed.append(functions.tanh(self.generator.encoder.word2embed(word)))\n",
    "    for word in target:\n",
    "        target_embed.append(functions.tanh(self.generator.decoder.word2embed(word)))\n",
    "\n",
    "    _, _, score, _ = self.discriminator(source_embed, target_embed, target_embed)\n",
    "    return score\n",
    "\n",
    "CSGANNMT.get_score = get_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اگر برنامه در گام آموزش باشد، کتابخانه لغات ورودی وخروجی بارگزاری می شود.سپس شبکه ماشین ترجمه عصبی مبتنی بر توجه اجرا شده و مقادیر وزنی از آن تهیه می گردد. بر اساس خروجی این اجرا و ورودی های دیگری همچون لغات ورودی و خروجی و پارامترهای دیگر لازم، شبکه مولد خصمانه که در بالا تعریف گردید را فراخوانی می نماییم. مقدار بهنیه شبکه تمییز دهنده از این طریق محاسبه می گردد. مقدار خطای شبکه تمییز دهنده، شبکه مولد، احتمال پیش بینی شبکه تمییز دهنده و پیش بینی شبکه مولد نیز برای هر بخش از جملات محاسبه می گردد. در نهایت نیز مدل برنامه حاوی لغات ورودی و خروجی، مدل وزن و مقدار بهینه شبکه تمییز دهنده و شبکه مولد ذخیره می شود.، "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    trace(\"Start Pre-Training ...\")\n",
    "    trace(\"Loading Vocabulary ...\")\n",
    "    source_vocabulary = Vocabulary.load(\"{}.source_vocabulary\".format(config.pre_model))\n",
    "    target_vocabulary = Vocabulary.load(\"{}.target_vocabulary\".format(config.pre_model))\n",
    "    config.source_vocabulary_size = source_vocabulary.size\n",
    "    config.target_vocabulary_size = target_vocabulary.size\n",
    "\n",
    "    trace(\"Making Model ...\")\n",
    "    pre_nmt = AttentionalNMT(config.source_vocabulary_size, config.target_vocabulary_size, config.embed_size, config.hidden_size, source_vocabulary, target_vocabulary, None, None, config.use_dropout, config.dropout_rate, None, False, None, config.library)\n",
    "    serializers.load_hdf5(\"{}.weights\".format(config.pre_model), pre_nmt)\n",
    "    \n",
    "    nmt = CSGANNMT(config.source_vocabulary_size, config.target_vocabulary_size, config.embed_size, config.hidden_size, source_vocabulary, target_vocabulary, None, None, config.use_dropout, config.dropout_rate, None, False, None, config.library, pre_nmt)\n",
    "    if config.use_gpu:\n",
    "        cuda.get_device(config.gpu_device).use()\n",
    "        nmt.to_gpu()\n",
    "\n",
    "    discriminator_opt = config.discriminator_optimizer\n",
    "    discriminator_opt.setup(nmt.discriminator)\n",
    "    discriminator_opt.add_hook(optimizer.WeightDecay(0.0001))\n",
    "\n",
    "    for epoch in range(config.epoch):\n",
    "        trace(\"Epoch {}/{}\".format(epoch + 1, config.epoch))\n",
    "        accum_loss_discriminator = 0.0\n",
    "        finished = 0\n",
    "        random.seed(epoch)\n",
    "        for batch_source, batch_target, batch_output in random_sorted_3parallel_batch(config.source_train, config.target_train, config.output_train, source_vocabulary, target_vocabulary, config.batch_size, config.pooling, config.library):\n",
    "            loss_generator, loss_discriminator, batch_predict_generator, batch_predict_discriminator_true, batch_predict_discriminator_generate = nmt(batch_source, batch_target, batch_output)\n",
    "            accum_loss_discriminator += loss_discriminator.data\n",
    "            nmt.zerograds()\n",
    "            loss_discriminator.backward()\n",
    "            discriminator_opt.update()\n",
    "\n",
    "            for source, target, predict_generator, predict_discriminator_true, predict_discriminator_generate in zip(convert_wordlist(batch_source, source_vocabulary), convert_wordlist(batch_target, target_vocabulary), convert_wordlist(batch_output, target_vocabulary), batch_predict_discriminator_true.data, batch_predict_discriminator_generate.data):\n",
    "                trace(\"Epoch {}/{}, Sample {}\".format(epoch + 1, config.epoch, finished + 1))\n",
    "                trace(\"Source                = {}\".format(source))\n",
    "                trace(\"Target                = {}\".format(target))\n",
    "                trace(\"Predict_Generator     = {}\".format(predict_generator))\n",
    "                trace(\"Predict_Discriminator = True:{} Generate:{}\".format(predict_discriminator_true, predict_discriminator_generate))\n",
    "                finished += 1\n",
    "\n",
    "        trace(\"accum_loss_discriminator = {}\".format(accum_loss_discriminator))\n",
    "        trace(\"Saving Model ...\")\n",
    "        model = \"{}.pretrain.{:03d}\".format(config.model, epoch + 1)\n",
    "        source_vocabulary.save(\"{}.source_vocabulary\".format(model))\n",
    "        target_vocabulary.save(\"{}.target_vocabulary\".format(model))\n",
    "        serializers.save_hdf5(\"{}.weights\".format(model), nmt)\n",
    "        serializers.save_hdf5(\"{}.optimizer_discriminator\".format(model), discriminator_opt)\n",
    "\n",
    "    trace(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در گام تست برنامه بعد از بارگزاری لغات ورودی و هدف، شبکه مولد خصمانه را اجرا می نماییم. مقدار وزن بعد از اجرا استخراج می گردد. در نهایت نیز فایل پیش بینی ذخیره می گردد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(config):\n",
    "    trace(\"Loading Vocabulary ...\")\n",
    "    source_vocabulary = Vocabulary.load(\"{}.source_vocabulary\".format(config.model))\n",
    "    target_vocabulary = Vocabulary.load(\"{}.target_vocabulary\".format(config.model))\n",
    "    config.source_vocabulary_size = source_vocabulary.size\n",
    "    config.target_vocabulary_size = target_vocabulary.size\n",
    "\n",
    "    trace(\"Loading Model ...\")\n",
    "    nmt = CSGANNMT(config.source_vocabulary_size, config.target_vocabulary_size, config.embed_size, config.hidden_size, source_vocabulary, target_vocabulary, None, None, False, 0.0, config.generation_limit, config.use_beamsearch, config.beam_size, config.library, None)\n",
    "    if config.use_gpu:\n",
    "        cuda.get_device(config.gpu_device).use()\n",
    "        nmt.to_gpu()\n",
    "    serializers.load_hdf5(\"{}.weights\".format(config.model), nmt)\n",
    "\n",
    "    trace(\"Generating Translation ...\")\n",
    "    finished = 0\n",
    "    \n",
    "    with open(config.predict_file, 'w') as ft:\n",
    "        for batch_source in mono_batch(config.source_file, source_vocabulary, 1, config.library):\n",
    "            trace(\"Sample {} ...\".format(finished + 1))\n",
    "            _, _, batch_predict, _, _ = nmt(batch_source, None)\n",
    "            for predict in convert_wordlist(batch_predict, target_vocabulary):\n",
    "                ft.write(\"{}\\n\".format(predict))\n",
    "                finished += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بر اساس ورودی شبکه تعیین می گردد که برنامه در گام آموزش، اعتبارسنجی و یا تست اجرا می شود. بر اساس هر یک از این حالت یک مدل پیش آموزش و مقادیری از پارامتری ها فراخوانی می شود. سپس یکی از توابع بالا اجرا می گردد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = Configuration(sys.argv[1], sys.argv[2])\n",
    "    if config.mode == \"train\":\n",
    "        config.pre_model = \"{}.{:03d}\".format(config.pre_model, config.pre_best_epoch)\n",
    "        train(config)\n",
    "    elif config.mode == \"test\":\n",
    "        trace(\"Start Testing ...\")\n",
    "        config.source_file = config.source_test\n",
    "        config.predict_file = \"{}.test_result.beam{}\".format(config.model, config.beam_size)\n",
    "        config.model = \"{}.{:03d}\".format(config.model, int(sys.argv[3]))\n",
    "        test(config)\n",
    "        trace(\"Finished.\")\n",
    "    elif config.mode == \"dev\":\n",
    "        trace(\"Start Developing ...\")\n",
    "        config.source_file = config.source_dev\n",
    "        model = config.model\n",
    "        if len(sys.argv) == 5:\n",
    "            start = int(sys.argv[3]) - 1\n",
    "            end = int(sys.argv[4])\n",
    "        else:\n",
    "            start = 0\n",
    "            end = config.epoch\n",
    "        for i in range(start, end):\n",
    "            config.model = \"{}.{:03d}\".format(model, i + 1)\n",
    "            trace(\"Model {}/{}\".format(i + 1, config.epoch))\n",
    "            config.predict_file = \"{}.dev_result\".format(config.model)\n",
    "            test(config)\n",
    "        trace(\"Finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
