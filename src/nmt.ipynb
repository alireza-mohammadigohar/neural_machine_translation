{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"اول کلاس کد مربوط به بخش انکدر شبکه ماشین ترجمه عصبی است. همانطور که در فایل متنی به تفصیل ارائه شده است، انکدر یک شبکه عصبی دو طرفه ال اس تی ام است\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from chainer import *\n",
    "from utilities import *\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Encoder(Chain):\n",
    "    #Bi-directional LSTM (forward + backward)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, source_vocabulary_size, embed_size, hidden_size, source_vocabulary, source_word2vec, use_dropout, dropout_rate, library):\n",
    "    super(Encoder, self).__init__(\n",
    "        word2embed = links.EmbedID(source_vocabulary_size, embed_size, ignore_label = -1),\n",
    "        embed2hidden_forward = links.LSTM(embed_size, hidden_size),\n",
    "        embed2hidden_backward = links.LSTM(embed_size, hidden_size),\n",
    "    )\n",
    "    if source_word2vec is not None:\n",
    "        for i in range(source_vocabulary_size):\n",
    "            word = source_vocabulary.id2word[i]\n",
    "            if word in source_word2vec:\n",
    "                self.word2embed.W.data[i] = source_word2vec[word]\n",
    "    self.vocabulary_size = source_vocabulary_size\n",
    "    self.embed_size = embed_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.use_dropout = use_dropout\n",
    "    self.dropout_rate = dropout_rate\n",
    "    self.library = library\n",
    "\n",
    "Encoder.__init__ = __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __call__(self, sentence):\n",
    "    return self.forward(sentence)[0]\n",
    "\n",
    "Encoder.__call__ = __call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(self, sentence):\n",
    "    embed_states = list()\n",
    "    hidden_backward_states = list()\n",
    "    hidden_states = list()\n",
    "    for word in sentence:\n",
    "        embed_states.append(functions.dropout(functions.tanh(self.word2embed(word)), ratio = self.dropout_rate))\n",
    "    for embed in embed_states[::-1]:\n",
    "        hidden_backward_states.insert(0, functions.dropout(functions.tanh(self.embed2hidden_backward(embed)), ratio = 0.0)) #False\n",
    "    for embed, hidden_backward in zip(embed_states, hidden_backward_states):\n",
    "        plus = functions.dropout(functions.tanh(self.embed2hidden_forward(embed)), ratio = 0.0) + hidden_backward #False\n",
    "        hidden_states.append(plus)\n",
    "    return hidden_states, embed_states\n",
    "\n",
    "Encoder.forward = forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_states(self):\n",
    "    self.embed2hidden_forward.reset_state()\n",
    "    self.embed2hidden_backward.reset_state()\n",
    "    \n",
    "Encoder.reset_states = reset_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"کلاس بعدی اقدام به ایجاد شبکه دیکدر می نماید. شبکه دیکدر در نظر گرفته شده یک شبکه عصبی یک لایه یک طرفه ال اس تی ام است. همچنین برای بالا بردن دقت عملکردی برنامه به شبکه یک لایه اتنشن نیز اضافه شده است\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(Chain):\n",
    "\t#Luong Global-Attention (dot)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, target_vocabulary_size, embed_size, hidden_size, target_vocabulary, target_word2vec, use_dropout, dropout_rate, generation_limit, use_beamsearch, beam_size, library):\n",
    "        super(Decoder, self).__init__(\n",
    "            encoder2decoder_init = links.LSTM(hidden_size, hidden_size),\n",
    "            word2embed = links.EmbedID(target_vocabulary_size, embed_size, ignore_label = -1),\n",
    "            embed_hidden_tilde2hidden = links.LSTM(embed_size + hidden_size, hidden_size),\n",
    "            attention_hidden2hidden_tilde = links.Linear(2 * hidden_size, hidden_size),\n",
    "            hidden_tilde2predict = links.Linear(hidden_size, target_vocabulary_size),\n",
    "        )\n",
    "        if target_word2vec is not None:\n",
    "            for i in range(target_vocabulary_size):\n",
    "                word = target_vocabulary.id2word[i]\n",
    "                if word in target_word2vec:\n",
    "                    self.word2embed.W.data[i] = target_word2vec[word]\n",
    "        self.vocabulary_size = target_vocabulary_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_dropout = use_dropout\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.generation_limit = generation_limit\n",
    "        self.use_beamsearch = use_beamsearch\n",
    "        self.beam_size = beam_size\n",
    "        self.library = library\n",
    "\n",
    "Decoder.__init__ = __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __call__(self, encoder_hidden_states, sentence):\n",
    "    return self.forward(encoder_hidden_states, sentence)[:2]\n",
    "\n",
    "Decoder.__call__ = __call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(self, encoder_hidden_states, sentence):\n",
    "    predicts = list()\n",
    "    target_embed_states = list()\n",
    "    predict_embed_states = list()\n",
    "    hidden_states = list()\n",
    "    attention_weights_matrix = list()\n",
    "    if sentence is not None:\n",
    "        loss = Variable(self.library.zeros((), dtype = self.library.float32))\n",
    "        for i, word in enumerate(sentence):\n",
    "            if i == 0:\n",
    "                hidden = functions.dropout(functions.tanh(self.encoder2decoder_init(encoder_hidden_states[0])), ratio = 0.0) #False\n",
    "                encoder_hidden_states = functions.dstack(encoder_hidden_states)\n",
    "                self.copy_states()\n",
    "            else:\n",
    "                previous_embed = functions.dropout(functions.tanh(self.word2embed(sentence[i - 1])), ratio = self.dropout_rate)\n",
    "                target_embed_states.append(previous_embed)\n",
    "                hidden = functions.dropout(functions.tanh(self.embed_hidden_tilde2hidden(functions.concat((previous_embed, hidden_tilde)))), ratio = 0.0) #False\n",
    "            attention_weights = functions.softmax(functions.batch_matmul(encoder_hidden_states, hidden, transa = True))\n",
    "            attention = functions.reshape(functions.batch_matmul(encoder_hidden_states, attention_weights), (encoder_hidden_states.shape[0], encoder_hidden_states.shape[1]))\n",
    "            hidden_tilde = functions.dropout(functions.tanh(self.attention_hidden2hidden_tilde(functions.concat((attention, hidden)))), ratio = self.dropout_rate)\n",
    "            hidden_states.append(hidden_tilde)\n",
    "            score = self.hidden_tilde2predict(hidden_tilde)\n",
    "            predict = functions.argmax(score, axis = 1)\n",
    "            loss += functions.softmax_cross_entropy(score, word, ignore_label = -1)\n",
    "            predict = functions.where(word.data == -1, word, predict)\n",
    "            predicts.append(predict.data)\n",
    "            predict_embed_states.append(functions.dropout(functions.tanh(self.word2embed(predict)), ratio = self.dropout_rate))\n",
    "        target_embed_states.append(functions.dropout(functions.tanh(self.word2embed(sentence[-1])), ratio = self.dropout_rate))\n",
    "        return loss, predicts, target_embed_states, predict_embed_states, hidden_states, None\n",
    "\n",
    "    elif not self.use_beamsearch:\n",
    "        while len(predicts) < self.generation_limit:\n",
    "            if len(predicts) == 0:\n",
    "                hidden = functions.tanh(self.encoder2decoder_init(encoder_hidden_states[0]))\n",
    "                encoder_hidden_states = functions.dstack(encoder_hidden_states)\n",
    "                self.copy_states()\n",
    "            else:\n",
    "                previous_embed = functions.tanh(self.word2embed(predict))\n",
    "                predict_embed_states.append(previous_embed)\n",
    "                hidden = functions.tanh(self.embed_hidden_tilde2hidden(functions.concat((previous_embed, hidden_tilde))))\n",
    "            attention_weights = functions.softmax(functions.batch_matmul(encoder_hidden_states, hidden, transa = True))\n",
    "            attention_weights_matrix.append(functions.reshape(attention_weights, (attention_weights.shape[0], attention_weights.shape[1])))\n",
    "            attention = functions.reshape(functions.batch_matmul(encoder_hidden_states, attention_weights), (encoder_hidden_states.shape[0], encoder_hidden_states.shape[1]))\n",
    "            hidden_tilde = functions.tanh(self.attention_hidden2hidden_tilde(functions.concat((attention, hidden))))\n",
    "            hidden_states.append(hidden_tilde)\n",
    "            score = self.hidden_tilde2predict(hidden_tilde)\n",
    "            predict = functions.argmax(score, axis = 1)\n",
    "            predicts.append(predict.data)\n",
    "            if predict.data[0] == 1:\n",
    "                break\n",
    "        predict_embed_states.append(functions.tanh(self.word2embed(predict)))\n",
    "        attention_weights_matrix = functions.stack(attention_weights_matrix, axis = 1)\n",
    "        return None, predicts, None, predict_embed_states, hidden_states, attention_weights_matrix\n",
    "\n",
    "    else:\n",
    "        initial_beam = [(0, None, list(), encoder_hidden_states, list(), list(), list())]\n",
    "        for _, _, sentence, _, predict_embed_states, hidden_states, attention_weights_matrix in sorted(self.n_forwards(initial_beam), key = lambda x: x[0].data / len(x[2]), reverse = True):\n",
    "            for word in sentence:\n",
    "                predicts.append(word.data)\n",
    "            attention_weights_matrix = functions.stack(attention_weights_matrix, axis = 1)\n",
    "            break\n",
    "        return None, predicts, None, predict_embed_states, hidden_states, attention_weights_matrix\n",
    "\n",
    "Decoder.forward = forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def n_forwards(self, initial_beam):\n",
    "    beam = [0] * self.generation_limit\n",
    "    for i in range(self.generation_limit):\n",
    "        beam[i] = list()\n",
    "        if i == 0:\n",
    "            new_beam = list()\n",
    "            for logprob, states, sentence, encoder_hidden_states, embed_states, hidden_states, attention_weights_matrix in initial_beam:\n",
    "                hidden = functions.tanh(self.encoder2decoder_init(encoder_hidden_states[0]))\n",
    "                encoder_hidden_states = functions.dstack(encoder_hidden_states)\n",
    "                self.copy_states()\n",
    "                attention_weights = functions.softmax(functions.batch_matmul(encoder_hidden_states, hidden, transa = True))\n",
    "                attention = functions.reshape(functions.batch_matmul(encoder_hidden_states, attention_weights), (encoder_hidden_states.shape[0], encoder_hidden_states.shape[1]))\n",
    "                hidden_tilde = functions.tanh(self.attention_hidden2hidden_tilde(functions.concat((attention, hidden))))\n",
    "                prob = functions.softmax(self.hidden_tilde2predict(hidden_tilde))\n",
    "                cell, hidden = self.get_states()\n",
    "                for predict in numpy.argsort(cuda.to_cpu(prob.data)[0])[-1:-self.beam_size-1:-1]:\n",
    "                    predict_variable = Variable(self.library.array([predict], dtype = self.library.int32))\n",
    "                    if predict == 1:\n",
    "                        new_beam.append((logprob + functions.log(prob[0][predict]), None, sentence + [predict_variable], encoder_hidden_states, embed_states + [functions.tanh(self.word2embed(predict_variable))], hidden_states + [hidden_tilde], attention_weights_matrix + [functions.reshape(attention_weights, (attention_weights.shape[0], attention_weights.shape[1]))])) \n",
    "                    else:\n",
    "                        new_beam.append((logprob + functions.log(prob[0][predict]), (cell, hidden, hidden_tilde), sentence + [predict_variable], encoder_hidden_states, embed_states, hidden_states + [hidden_tilde], attention_weights_matrix + [functions.reshape(attention_weights, (attention_weights.shape[0], attention_weights.shape[1]))]))\n",
    "            for _, (logprob, states, sentence, encoder_hidden_states, embed_states, hidden_states, attention_weights_matrix) in zip(range(self.beam_size), sorted(new_beam, key = lambda x: x[0].data / len(x[2]), reverse = True)):\n",
    "                beam[i].append((logprob, states, sentence, encoder_hidden_states, embed_states, hidden_states, attention_weights_matrix))\n",
    "        else:\n",
    "            new_beam = list()\n",
    "            for logprob, states, sentence, encoder_hidden_states, embed_states, hidden_states, attention_weights_matrix in beam[i - 1]:\n",
    "                if states is not None:\n",
    "                    previous_cell, previous_hidden, previous_hidden_tilde = states\n",
    "                    self.embed_hidden_tilde2hidden.set_state(previous_cell, previous_hidden)\n",
    "                    previous_embed = functions.tanh(self.word2embed(sentence[-1]))\n",
    "                    hidden = functions.tanh(self.embed_hidden_tilde2hidden(functions.concat((previous_embed, previous_hidden_tilde))))\n",
    "                    attention_weights = functions.softmax(functions.batch_matmul(encoder_hidden_states, hidden, transa = True))\n",
    "                    attention = functions.reshape(functions.batch_matmul(encoder_hidden_states, attention_weights), (encoder_hidden_states.shape[0], encoder_hidden_states.shape[1]))\n",
    "                    hidden_tilde = functions.tanh(self.attention_hidden2hidden_tilde(functions.concat((attention, hidden))))\n",
    "                    prob = functions.softmax(self.hidden_tilde2predict(hidden_tilde))\n",
    "                    cell, hidden = self.get_states()\n",
    "                    for predict in numpy.argsort(cuda.to_cpu(prob.data)[0])[-1:-self.beam_size-1:-1]:\n",
    "                        predict_variable = Variable(self.library.array([predict], dtype = self.library.int32))\n",
    "                        if predict == 1:\n",
    "                            new_beam.append((logprob + functions.log(prob[0][predict]), None, sentence + [predict_variable], encoder_hidden_states, embed_states + [previous_embed, functions.tanh(self.word2embed(predict_variable))], hidden_states + [hidden_tilde], attention_weights_matrix + [functions.reshape(attention_weights, (attention_weights.shape[0], attention_weights.shape[1]))])) \n",
    "                        else:\n",
    "                            new_beam.append((logprob + functions.log(prob[0][predict]), (cell, hidden, hidden_tilde), sentence + [predict_variable], encoder_hidden_states, embed_states + [previous_embed], hidden_states + [hidden_tilde], attention_weights_matrix + [functions.reshape(attention_weights, (attention_weights.shape[0], attention_weights.shape[1]))]))\n",
    "                else:\n",
    "                    new_beam.append((logprob, None, sentence, encoder_hidden_states, embed_states, hidden_states, attention_weights_matrix))\n",
    "            for _, (logprob, states, sentence, encoder_hidden_states, embed_states, hidden_states, attention_weights_matrix) in zip(range(self.beam_size), sorted(new_beam, key = lambda x: x[0].data / len(x[2]), reverse = True)):\n",
    "                beam[i].append((logprob, states, sentence, encoder_hidden_states, embed_states, hidden_states, attention_weights_matrix))\n",
    "    return beam[-1]\n",
    "\n",
    "Decoder.n_forwards = n_forwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_states(self):\n",
    "    cell = copy.deepcopy(self.embed_hidden_tilde2hidden.c)\n",
    "    hidden = copy.deepcopy(self.embed_hidden_tilde2hidden.h)\n",
    "    return cell, hidden\n",
    "\n",
    "Decoder.get_states = get_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_states(self):\n",
    "    cell = self.encoder2decoder_init.c\n",
    "    hidden = self.encoder2decoder_init.h\n",
    "    self.embed_hidden_tilde2hidden.set_state(cell, hidden)\n",
    "    \n",
    "Decoder.copy_states = copy_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_states(self):\n",
    "    self.encoder2decoder_init.reset_state()\n",
    "    self.embed_hidden_tilde2hidden.reset_state()\n",
    "\n",
    "Decoder.reset_states = reset_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"کلاس زیر نیز به تعریف ماشین ترجمه عصبی مبتنی بر اتنشن می پردازد. برای تعیین وضعیت های مورد توجه مقادیر وضعیت ها از شبکه های انکدر و دیکدر دریافت می شود و با بررسی پیش بینی و خطای شبکه حالت ها مورد توجه برای شبکه تعیین می گردد\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionalNMT(Chain):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self, source_vocabulary_size, target_vocabulary_size, embed_size, hidden_size, source_vocabulary, target_vocabulary, source_word2vec, target_word2vec, use_dropout, dropout_rate, generation_limit, use_beamsearch, beam_size, library):\n",
    "    super(AttentionalNMT, self).__init__(\n",
    "        encoder = Encoder(source_vocabulary_size, embed_size, hidden_size, source_vocabulary, source_word2vec, use_dropout, dropout_rate, library),\n",
    "        decoder = Decoder(target_vocabulary_size, embed_size, hidden_size, target_vocabulary, target_word2vec, use_dropout, dropout_rate, generation_limit, use_beamsearch, beam_size, library),\n",
    "\t)\n",
    "    \n",
    "AttentionalNMT.__init__ = __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __call__(self, batch_source, batch_target):\n",
    "    self.reset_states()\n",
    "    encoder_hidden_states = self.encoder(batch_source)\n",
    "    loss, predicts = self.decoder(encoder_hidden_states, batch_target)\n",
    "    return loss, predicts\n",
    "\n",
    "AttentionalNMT.__call__ = __call__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(self, batch_source, batch_target):\n",
    "    self.reset_states()\n",
    "    encoder_hidden_states, source_embed_states = self.encoder.forward(batch_source)\n",
    "    loss, predicts, target_embed_states, predict_embed_states, decoder_hidden_states, attention_matrix = self.decoder.forward(encoder_hidden_states, batch_target)\n",
    "    return loss, predicts, source_embed_states, target_embed_states, predict_embed_states, encoder_hidden_states, decoder_hidden_states, attention_matrix\n",
    "\n",
    "AttentionalNMT.forward = forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reset_states(self):\n",
    "    self.encoder.reset_states()\n",
    "    self.decoder.reset_states()\n",
    "    \n",
    "AttentionalNMT.reset_states = reset_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"تابع زیر اقدام به استخراج کانفیگ های تعریف شده برای پارامترهای شبکه ماشین ترجمه عصبی می نماید. همچنین فایل های مرتبط برای برنامه شامل فایل لغات، بردارهای جاسازی لازم ساخته و یا بارگزاری می شود. در نهایت خروجی شبکه شامل خطا، مدل، وزن و مدل بهینه شبکه ذخیره می شود\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    if len(sys.argv) == 4:\n",
    "        start = int(sys.argv[3]) - 1\n",
    "        trace(\"Start Re-Training ...\")\n",
    "        trace(\"Loading Vocabulary ...\")\n",
    "        source_vocabulary = Vocabulary.load(\"{}.{:03d}.source_vocabulary\".format(config.model, start))\n",
    "        target_vocabulary = Vocabulary.load(\"{}.{:03d}.target_vocabulary\".format(config.model, start))\n",
    "        source_word2vec = None\n",
    "        target_word2vec = None\n",
    "    else:\n",
    "        start = 0\n",
    "        trace(\"Start Training ...\")\n",
    "        trace(\"Making Vocabulary ...\")\n",
    "        source_vocabulary = Vocabulary.make(config.source_train, config.source_vocabulary_size)\n",
    "        target_vocabulary = Vocabulary.make(config.target_train, config.target_vocabulary_size)\n",
    "\n",
    "        if config.use_word2vec == \"Load\":\n",
    "            trace(\"Loading Word2vec ...\")\n",
    "            source_word2vec = load_word2vec(config.source_word2vec_file)\n",
    "            target_word2vec = load_word2vec(config.target_word2vec_file)\n",
    "            save_word2vec(source_word2vec, \"{}.source_word2vec\".format(config.model))\n",
    "            save_word2vec(target_word2vec, \"{}.target_word2vec\".format(config.model))\n",
    "        elif config.use_word2vec == \"Make\":\n",
    "            trace(\"Making Word2vec ...\")\n",
    "            source_word2vec = make_word2vec(config.source_train, config.embed_size)\n",
    "            target_word2vec = make_word2vec(config.target_train, config.embed_size)\n",
    "            save_word2vec(source_word2vec, \"{}.source_word2vec\".format(config.model))\n",
    "            save_word2vec(target_word2vec, \"{}.target_word2vec\".format(config.model))\n",
    "        else:\n",
    "            source_word2vec = None\n",
    "            target_word2vec = None\n",
    "\n",
    "    config.source_vocabulary_size = source_vocabulary.size\n",
    "    config.target_vocabulary_size = target_vocabulary.size\n",
    "    \n",
    "    trace(\"Making Model ...\")\n",
    "    nmt = AttentionalNMT(config.source_vocabulary_size, config.target_vocabulary_size, config.embed_size, config.hidden_size, source_vocabulary, target_vocabulary, source_word2vec, target_word2vec, config.use_dropout, config.dropout_rate, None, False, None, config.library)\n",
    "    if config.use_gpu:\n",
    "        cuda.get_device(config.gpu_device).use()\n",
    "        nmt.to_gpu()\n",
    "\n",
    "    opt = config.optimizer\n",
    "    opt.setup(nmt)\n",
    "    opt.add_hook(optimizer.GradientClipping(5))\n",
    "\n",
    "\n",
    "    if start != 0:\n",
    "        serializers.load_hdf5(\"{}.{:03d}.weights\".format(config.model, start), nmt)\n",
    "        serializers.load_hdf5(\"{}.{:03d}.optimizer\".format(config.model, start), opt)\n",
    "\n",
    "    for epoch in range(start, config.epoch):\n",
    "        trace(\"Epoch {}/{}\".format(epoch + 1, config.epoch))\n",
    "        accum_loss = 0.0\n",
    "        finished = 0\n",
    "        random.seed(epoch)\n",
    "        for batch_source, batch_target in random_sorted_parallel_batch(config.source_train, config.target_train, source_vocabulary, target_vocabulary, config.batch_size, config.pooling, config.library):\n",
    "            nmt.zerograds()\n",
    "            loss, batch_predict = nmt(batch_source, batch_target)\n",
    "            accum_loss += loss.data\n",
    "            loss.backward()\n",
    "            opt.update()\n",
    "\n",
    "            for source, target, predict in zip(convert_wordlist(batch_source, source_vocabulary), convert_wordlist(batch_target, target_vocabulary), convert_wordlist(batch_predict, target_vocabulary)):\n",
    "                trace(\"Epoch {}/{}, Sample {}\".format(epoch + 1, config.epoch, finished + 1))\n",
    "                trace(\"Source  = {}\".format(source))\n",
    "                trace(\"Target  = {}\".format(target))\n",
    "                trace(\"Predict = {}\".format(predict))\n",
    "                finished += 1\n",
    "\n",
    "        trace(\"accum_loss = {}\".format(accum_loss))\n",
    "        trace(\"Saving Model ...\")\n",
    "        model = \"{}.{:03d}\".format(config.model, epoch + 1)\n",
    "        source_vocabulary.save(\"{}.source_vocabulary\".format(model))\n",
    "        target_vocabulary.save(\"{}.target_vocabulary\".format(model))\n",
    "        serializers.save_hdf5(\"{}.weights\".format(model), nmt)\n",
    "        serializers.save_hdf5(\"{}.optimizer\".format(model), opt)\n",
    "\n",
    "    trace(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"در صورتی که قصد تست شبکه را داشته باشیم تابع زیر فراخوانی می شود. با توجه به تابع مقادیر پارامترهای متناسب و کلمات ورودی و خروجی شبکه خواهنده شده. ترجمه شبکه تهیه می شود و مقدار خطای شبکه با توحه به مقدار پارامتر جستجو مشخص می گردد\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(config):\n",
    "    trace(\"Loading Vocabulary ...\")\n",
    "    source_vocabulary = Vocabulary.load(\"{}.source_vocabulary\".format(config.model))\n",
    "    target_vocabulary = Vocabulary.load(\"{}.target_vocabulary\".format(config.model))\n",
    "    config.source_vocabulary_size = source_vocabulary.size\n",
    "    config.target_vocabulary_size = target_vocabulary.size\n",
    "\n",
    "    trace(\"Loading Model ...\")\n",
    "    nmt = AttentionalNMT(config.source_vocabulary_size, config.target_vocabulary_size, config.embed_size, config.hidden_size, source_vocabulary, target_vocabulary, None, None, False, 0.0, config.generation_limit, config.use_beamsearch, config.beam_size, config.library)\n",
    "    if config.use_gpu:\n",
    "        cuda.get_device(config.gpu_device).use()\n",
    "        nmt.to_gpu()\n",
    "    serializers.load_hdf5(\"{}.weights\".format(config.model), nmt)\n",
    "\n",
    "    trace(\"Generating Translation ...\")\n",
    "    finished = 0\n",
    "    \n",
    "    with open(config.predict_file, 'w') as ft:\n",
    "        for batch_source in mono_batch(config.source_file, source_vocabulary, 1, config.library):\n",
    "            trace(\"Sample {} ...\".format(finished + 1))\n",
    "            _, batch_predict, _, _, _, _, _, batch_attention = nmt.forward(batch_source, None)\n",
    "            for source, predict, attention in zip(convert_wordlist(batch_source, source_vocabulary), convert_wordlist(batch_predict, target_vocabulary), batch_attention.data):\n",
    "                ft.write(\"{}\\n\".format(predict))\n",
    "                finished += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in below part: we havd two parameters. \n",
    "    argv1: define mode of run, you can use one of these modes: 'train' , 'dev' , 'test'\n",
    "    argv2: define path of config file. this file contains all parameters value and dataset address (the path is important and must be check based on you system location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-26 10:52:32.648802 ... Start Training ...\n",
      "2019-11-26 10:52:32.649847 ... Making Vocabulary ...\n",
      "2019-11-26 10:52:32.927277 ... Making Word2vec ...\n",
      "2019-11-26 10:52:40.094559 ... Making Model ...\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n",
      "2019-11-26 10:52:41.350716 ... Epoch 1/10\n",
      "2019-11-26 10:52:45.559621 ... Epoch 1/10, Sample 1\n",
      "2019-11-26 10:52:45.560645 ... Source  = 彼 は 消防 士 に な ろ う と 決心 し た 。\n",
      "2019-11-26 10:52:45.561545 ... Target  = he made up his mind to be a fireman .\n",
      "2019-11-26 10:52:45.562387 ... Predict = sob answer weep now now now now pendant pendant misery misery   \n",
      "2019-11-26 10:52:45.563070 ... Epoch 1/10, Sample 2\n",
      "2019-11-26 10:52:45.563940 ... Source  = 彼 が この 質問 に 答え る こと は 容易 で す 。\n",
      "2019-11-26 10:52:45.565662 ... Target  = it is easy for him to answer this question .\n",
      "2019-11-26 10:52:45.566193 ... Predict = died believes believes believes protested protested believes believes evident enables enables   \n",
      "2019-11-26 10:52:45.566897 ... Epoch 1/10, Sample 3\n",
      "2019-11-26 10:52:45.567343 ... Source  = 田園 を 歩 く の は 楽し い と 思 っ た 。\n",
      "2019-11-26 10:52:45.567826 ... Target  = i found it pleasant walking in the country .\n",
      "2019-11-26 10:52:45.568472 ... Predict = answer answer answer answer answer answer parentage answer answer answer    \n",
      "2019-11-26 10:52:45.569122 ... Epoch 1/10, Sample 4\n",
      "2019-11-26 10:52:45.569602 ... Source  = 彼 は その 旅行 の ため に お 金 を 貯め た 。\n",
      "2019-11-26 10:52:45.570076 ... Target  = he saved money for the trip .\n",
      "2019-11-26 10:52:45.570581 ... Predict = a weep grappled weep weep grappled grappled grappled      \n",
      "2019-11-26 10:52:45.571243 ... Epoch 1/10, Sample 5\n",
      "2019-11-26 10:52:45.571721 ... Source  = 彼 は 私 たち を とても よく 知 っ て い る 。\n",
      "2019-11-26 10:52:45.572189 ... Target  = he knows us very well .\n",
      "2019-11-26 10:52:45.572709 ... Predict = answer answer answer answer answer answer answer       \n",
      "2019-11-26 10:52:45.573358 ... Epoch 1/10, Sample 6\n",
      "2019-11-26 10:52:45.589715 ... Source  = 彼女 は 親切 に 道 を 教え て くれ ま し た 。\n",
      "2019-11-26 10:52:45.590431 ... Target  = she was kind enough to show me the way .\n",
      "2019-11-26 10:52:45.591018 ... Predict = merchant answer answer pendant pendant pendant seemed seemed seemed seemed seemed   \n",
      "2019-11-26 10:52:45.591752 ... Epoch 1/10, Sample 7\n",
      "2019-11-26 10:52:45.592236 ... Source  = 私 は 彼 の 望 む こと を 理解 でき な い 。\n",
      "2019-11-26 10:52:45.592756 ... Target  = i can 't make out what he wants .\n",
      "2019-11-26 10:52:45.593185 ... Predict = europe answer dear dear prior answer answer answer answer answer    \n",
      "2019-11-26 10:52:45.593866 ... Epoch 1/10, Sample 8\n",
      "2019-11-26 10:52:45.600627 ... Source  = 私 の 母 は 年 の 割 に 若 く 見え る 。\n",
      "2019-11-26 10:52:45.601643 ... Target  = my mother looks young for her age .\n",
      "2019-11-26 10:52:45.602163 ... Predict = answer answer answer answer answer a answer answer answer     \n",
      "2019-11-26 10:52:45.605017 ... Epoch 1/10, Sample 9\n",
      "2019-11-26 10:52:45.607693 ... Source  = 私 達 は 英語 を 三 年間 勉強 し て い る 。\n",
      "2019-11-26 10:52:45.608325 ... Target  = we have been studying english for three years .\n",
      "2019-11-26 10:52:45.610476 ... Predict = answer answer answer answer answer answer pendant pendant pendant pendant    \n",
      "2019-11-26 10:52:45.611219 ... Epoch 1/10, Sample 10\n",
      "2019-11-26 10:52:45.616602 ... Source  = 最近 に な っ て 初めて 彼女 は 考え を 変え た 。\n",
      "2019-11-26 10:52:45.617314 ... Target  = it was not until recently that she changed her mind .\n",
      "2019-11-26 10:52:45.617812 ... Predict = answer answer answer answer answer pendant pendant pendant pendant answer grappled grappled  \n",
      "2019-11-26 10:52:45.619068 ... Epoch 1/10, Sample 11\n",
      "2019-11-26 10:52:45.620455 ... Source  = 彼 に 真実 を はな す と は 彼女 は 正直 だ 。\n",
      "2019-11-26 10:52:45.626193 ... Target  = it is honest of her to tell him the truth .\n",
      "2019-11-26 10:52:45.627173 ... Predict = answer answer answer answer protested answer enables enables enables enables enables enables  \n",
      "2019-11-26 10:52:45.628102 ... Epoch 1/10, Sample 12\n",
      "2019-11-26 10:52:45.628670 ... Source  = わたし 今 、 東京 で 仕事 を し て い る の 。\n",
      "2019-11-26 10:52:45.629184 ... Target  = i 'm working in tokyo now .\n",
      "2019-11-26 10:52:45.629744 ... Predict = answer answer answer answer answer answer answer answer      \n",
      "2019-11-26 10:52:45.630522 ... Epoch 1/10, Sample 13\n",
      "2019-11-26 10:52:45.631113 ... Source  = 彼 は どんな 職業 に 就 い て い ま す か 。\n",
      "2019-11-26 10:52:45.631561 ... Target  = what line is he in ?\n",
      "2019-11-26 10:52:45.632374 ... Predict = answer answer evident answer answer evident evident       \n",
      "2019-11-26 10:52:45.633090 ... Epoch 1/10, Sample 14\n",
      "2019-11-26 10:52:45.633561 ... Source  = 今 は あまり 話 し た い 気 が し な い 。\n",
      "2019-11-26 10:52:45.634053 ... Target  = i don 't feel much like talking right now .\n",
      "2019-11-26 10:52:45.641236 ... Predict = answer answer answer answer answer answer answer answer nimble nimble nimble   \n",
      "2019-11-26 10:52:45.641991 ... Epoch 1/10, Sample 15\n",
      "2019-11-26 10:52:45.642487 ... Source  = 彼 が 姿 を 見せ る まで ここ で 待 と う 。\n",
      "2019-11-26 10:52:45.642982 ... Target  = let 's wait here until he turns up .\n",
      "2019-11-26 10:52:45.643435 ... Predict = answer duck prior duck seemed parentage answer answer 70,000 answer    \n",
      "2019-11-26 10:52:45.644038 ... Epoch 1/10, Sample 16\n",
      "2019-11-26 10:52:45.644595 ... Source  = 彼女 に それ を 言 う の は 気 が 引け る 。\n",
      "2019-11-26 10:52:45.645095 ... Target  = i don 't feel like telling her about it .\n",
      "2019-11-26 10:52:45.645491 ... Predict = answer answer answer incorporated answer incorporated answer answer dine answer enables   \n",
      "2019-11-26 10:52:45.646159 ... Epoch 1/10, Sample 17\n",
      "2019-11-26 10:52:45.646674 ... Source  = 君 が ここ に い る 限り 、 僕 は のこ る 。\n",
      "2019-11-26 10:52:45.647131 ... Target  = as long as you 're here , i 'll stay .\n",
      "2019-11-26 10:52:45.651771 ... Predict = answer answer answer answer answer answer parentage pendant pendant pendant pendant pendant  \n",
      "2019-11-26 10:52:45.653364 ... Epoch 1/10, Sample 18\n",
      "2019-11-26 10:52:45.654701 ... Source  = 彼 は あす は 来 られ る か も しれ な い 。\n",
      "2019-11-26 10:52:45.655513 ... Target  = he may be able to come tomorrow .\n",
      "2019-11-26 10:52:45.656477 ... Predict = answer answer answer answer answer prior answer prior prior     \n",
      "2019-11-26 10:52:45.657590 ... Epoch 1/10, Sample 19\n",
      "2019-11-26 10:52:45.660638 ... Source  = 私 は 今日 の 午後 メアリー と 会 う つもり で す 。\n",
      "2019-11-26 10:52:45.661195 ... Target  = i 'm going to see mary this afternoon .\n",
      "2019-11-26 10:52:45.661664 ... Predict = answer answer answer answer answer frantically towel towel towel towel    \n",
      "2019-11-26 10:52:45.662329 ... Epoch 1/10, Sample 20\n",
      "2019-11-26 10:52:45.662832 ... Source  = 私 は １ 日 中 手紙 を 書 い て い た 。\n",
      "2019-11-26 10:52:45.663330 ... Target  = i have been writing letters all day long .\n",
      "2019-11-26 10:52:45.663759 ... Predict = answer answer answer answer answer answer grappled grappled seemed grappled    \n",
      "2019-11-26 10:52:45.664402 ... Epoch 1/10, Sample 21\n",
      "2019-11-26 10:52:45.664920 ... Source  = 学生 は 遅刻 し な い よう に す べ き だ 。\n",
      "2019-11-26 10:52:45.665384 ... Target  = students should try not to be late .\n",
      "2019-11-26 10:52:45.665875 ... Predict = answer answer prior prior prior prior answer pendant pendant     \n",
      "2019-11-26 10:52:45.666610 ... Epoch 1/10, Sample 22\n",
      "2019-11-26 10:52:45.667169 ... Source  = 彼 は フランス 語 を 勉強 し よ う と し た 。\n",
      "2019-11-26 10:52:45.667620 ... Target  = he tried to learn french .\n",
      "2019-11-26 10:52:45.675494 ... Predict = europe answer answer church died pendant stress       \n",
      "2019-11-26 10:52:45.676533 ... Epoch 1/10, Sample 23\n",
      "2019-11-26 10:52:45.677047 ... Source  = 彼 が 成功 する と だれ が 保証 でき よ う か 。\n",
      "2019-11-26 10:52:45.677476 ... Target  = who can guarantee his success ?\n",
      "2019-11-26 10:52:45.677931 ... Predict = low low low low now frantically frantically       \n",
      "2019-11-26 10:52:45.678561 ... Epoch 1/10, Sample 24\n",
      "2019-11-26 10:52:45.679065 ... Source  = 彼 は 父 の 死後 、 母 の 世話 を し た 。\n",
      "2019-11-26 10:52:45.679490 ... Target  = he cared for his mother after his father died .\n",
      "2019-11-26 10:52:45.681909 ... Predict = a answer answer pendant a pendant pendant a enables enables enables   \n",
      "2019-11-26 10:52:45.683217 ... Epoch 1/10, Sample 25\n",
      "2019-11-26 10:52:45.684196 ... Source  = 私 達 は この 椅子 を ただ で 手 に 入れ た 。\n",
      "2019-11-26 10:52:45.685255 ... Target  = we got this chair free .\n",
      "2019-11-26 10:52:45.686096 ... Predict = partners answer spots july july july enables       \n",
      "2019-11-26 10:52:45.686843 ... Epoch 1/10, Sample 26\n",
      "2019-11-26 10:52:45.687521 ... Source  = 彼 は 食べ すぎ な い よう に し て い る 。\n",
      "2019-11-26 10:52:45.689453 ... Target  = he makes it a rule not to eat too much .\n",
      "2019-11-26 10:52:45.689933 ... Predict = answer answer answer answer answer pendant seemed prior seemed seemed seemed pendant  \n",
      "2019-11-26 10:52:45.690568 ... Epoch 1/10, Sample 27\n",
      "2019-11-26 10:52:45.692073 ... Source  = 私 は たって バス を 待 っ て い ま し た 。\n",
      "2019-11-26 10:52:45.692519 ... Target  = i stood waiting for a bus .\n",
      "2019-11-26 10:52:45.692945 ... Predict = answer answer answer answer merchant towel seemed towel      \n",
      "2019-11-26 10:52:45.694647 ... Epoch 1/10, Sample 28\n",
      "2019-11-26 10:52:45.695089 ... Source  = 私 の 努力 は 全て 役 に 立 た な かっ た 。\n",
      "2019-11-26 10:52:45.696381 ... Target  = all my efforts went for nothing .\n",
      "2019-11-26 10:52:45.696810 ... Predict = answer answer answer answer grappled satisfied pendant grappled      \n",
      "2019-11-26 10:52:45.697433 ... Epoch 1/10, Sample 29\n",
      "2019-11-26 10:52:45.697880 ... Source  = お 酒 を 飲 ん で も い い で す か 。\n",
      "2019-11-26 10:52:45.698304 ... Target  = can i drink alcohol ?\n",
      "2019-11-26 10:52:45.698727 ... Predict = prior prior removed removed removed removed        \n",
      "2019-11-26 10:52:45.699357 ... Epoch 1/10, Sample 30\n",
      "2019-11-26 10:52:45.699799 ... Source  = マイク に は ２人 の 女性 の 友人 が い ま す 。\n",
      "2019-11-26 10:52:45.700242 ... Target  = mike has two girl friends .\n",
      "2019-11-26 10:52:45.700664 ... Predict = answer answer answer answer answer frantically frantically       \n",
      "2019-11-26 10:52:45.706699 ... Epoch 1/10, Sample 31\n",
      "2019-11-26 10:52:45.708640 ... Source  = 僕 の 言 う 事 を 良 く 聞 い て くれ 。\n",
      "2019-11-26 10:52:45.709149 ... Target  = hang on my lips .\n",
      "2019-11-26 10:52:45.709589 ... Predict = merchant died died now now now        \n",
      "2019-11-26 10:52:45.710228 ... Epoch 1/10, Sample 32\n",
      "2019-11-26 10:52:45.710685 ... Source  = お しゃべり は やめ て 仕事 を す ま せ なさ い 。\n",
      "2019-11-26 10:52:45.711180 ... Target  = stop chattering and finish your work .\n",
      "2019-11-26 10:52:45.711663 ... Predict = merchant merchant vehicles vehicles evident evident evident evident      \n",
      "2019-11-26 10:52:45.712387 ... Epoch 1/10, Sample 33\n",
      "2019-11-26 10:52:45.712895 ... Source  = 忙し く て そんな ところ まで 手 が 回 ら な い 。\n",
      "2019-11-26 10:52:45.713382 ... Target  = we 're too busy to attend to such detail .\n",
      "2019-11-26 10:52:45.714050 ... Predict = answer answer answer answer answer prior answer prior evident answer answer   \n",
      "2019-11-26 10:52:45.714709 ... Epoch 1/10, Sample 34\n",
      "2019-11-26 10:52:45.715165 ... Source  = 日本 の 音楽 に は 興味 が あ り ま す か 。\n",
      "2019-11-26 10:52:45.715618 ... Target  = are you interested in japanese music ?\n",
      "2019-11-26 10:52:45.716134 ... Predict = doubts protested dear frantically frantically frantically frantically frantically      \n",
      "2019-11-26 10:52:45.716810 ... Epoch 1/10, Sample 35\n",
      "2019-11-26 10:52:45.717287 ... Source  = 至急 話 し た い こと が あ る の で す 。\n",
      "2019-11-26 10:52:45.717831 ... Target  = i have something to tell him quickly .\n",
      "2019-11-26 10:52:45.718328 ... Predict = dear answer answer answer jogging jogging 70,000 70,000 answer     \n",
      "2019-11-26 10:52:45.718998 ... Epoch 1/10, Sample 36\n",
      "2019-11-26 10:52:45.719426 ... Source  = 願い が 現実 に な る と よ い の だ が 。\n",
      "2019-11-26 10:52:45.719933 ... Target  = i hope my dream will come true .\n",
      "2019-11-26 10:52:45.720397 ... Predict = trusted trusted trusted trusted trusted trusted frantically frantically frantically     \n",
      "2019-11-26 10:52:45.721080 ... Epoch 1/10, Sample 37\n",
      "2019-11-26 10:52:45.721484 ... Source  = 彼 は 冗談 の つもり で そう 言 っ た だけ だ 。\n",
      "2019-11-26 10:52:45.721909 ... Target  = he said so only by way of a joke .\n",
      "2019-11-26 10:52:45.722317 ... Predict = answer answer answer answer answer answer answer pendant pendant pendant defended   \n",
      "2019-11-26 10:52:45.722925 ... Epoch 1/10, Sample 38\n",
      "2019-11-26 10:52:45.723353 ... Source  = 車 が 故障 し た の で 私 は 遅刻 し た 。\n",
      "2019-11-26 10:52:45.723765 ... Target  = i was late because my car broke down .\n",
      "2019-11-26 10:52:45.724229 ... Predict = answer answer answer answer pendant pendant pendant pendant enables enables    \n",
      "2019-11-26 10:52:45.724980 ... Epoch 1/10, Sample 39\n",
      "2019-11-26 10:52:45.725448 ... Source  = 英国 へ 行 っ た こと が あ り ま す か 。\n",
      "2019-11-26 10:52:45.725976 ... Target  = have you ever been to britain ?\n",
      "2019-11-26 10:52:45.726383 ... Predict = answer answer 70,000 70,000 answer frantically frantically frantically      \n",
      "2019-11-26 10:52:45.727063 ... Epoch 1/10, Sample 40\n",
      "2019-11-26 10:52:45.727534 ... Source  = 彼 に は 来年 外国 へ 行 く 計画 が あ る 。\n",
      "2019-11-26 10:52:45.728133 ... Target  = he has a plan to go abroad next year .\n",
      "2019-11-26 10:52:45.728528 ... Predict = answer answer answer answer answer answer frantically frantically frantically frantically frantically   \n",
      "2019-11-26 10:52:45.729338 ... Epoch 1/10, Sample 41\n",
      "2019-11-26 10:52:45.730288 ... Source  = あなた の 帽子 は 私 の に 似 て い ま す 。\n",
      "2019-11-26 10:52:45.730735 ... Target  = your hat is similar to mine .\n",
      "2019-11-26 10:52:45.731211 ... Predict = answer manage debate protested protested prior evident towel      \n",
      "2019-11-26 10:52:45.731881 ... Epoch 1/10, Sample 42\n",
      "2019-11-26 10:52:45.738371 ... Source  = 雪 で な けれ ば 、 父 は 帰宅 し ま す 。\n",
      "2019-11-26 10:52:45.738975 ... Target  = barring snow , father will come home .\n",
      "2019-11-26 10:52:45.739434 ... Predict = answer answer answer answer answer prior pendant pendant pendant     \n",
      "2019-11-26 10:52:45.740168 ... Epoch 1/10, Sample 43\n",
      "2019-11-26 10:52:45.740650 ... Source  = 私 の 猫 が テーブル の 下 から 出 て き た 。\n",
      "2019-11-26 10:52:45.741101 ... Target  = my cat has come out from under the table .\n",
      "2019-11-26 10:52:45.741563 ... Predict = answer manage answer answer grappled grappled grappled towel towel towel towel   \n",
      "2019-11-26 10:52:45.761107 ... Epoch 1/10, Sample 44\n",
      "2019-11-26 10:52:45.762166 ... Source  = 宿題 の 一番 最後 の 問題 を や っ た か い 。\n",
      "2019-11-26 10:52:45.763126 ... Target  = did you do the last problem of the homework ?\n",
      "2019-11-26 10:52:45.763742 ... Predict = answer answer answer prior answer prior answer up-to-date answer towel parentage   \n",
      "2019-11-26 10:52:45.764428 ... Epoch 1/10, Sample 45\n",
      "2019-11-26 10:52:45.764927 ... Source  = 彼 の 息子 は 怠け者 で 役 に 立 た な い 。\n",
      "2019-11-26 10:52:45.765393 ... Target  = his son is lazy and good for nothing .\n",
      "2019-11-26 10:52:45.765973 ... Predict = answer answer answer answer answer browns browns pendant pendant grappled    \n",
      "2019-11-26 10:52:45.766744 ... Epoch 1/10, Sample 46\n",
      "2019-11-26 10:52:45.767760 ... Source  = 私 は ニュース を 聞 く ため に ラジオ を つけ た 。\n",
      "2019-11-26 10:52:45.768465 ... Target  = i turned on the radio to listen to the news .\n",
      "2019-11-26 10:52:45.769185 ... Predict = propose weep weep weep towel towel towel towel towel towel towel towel  \n",
      "2019-11-26 10:52:45.770119 ... Epoch 1/10, Sample 47\n",
      "2019-11-26 10:52:45.770710 ... Source  = 町 に き た とき は どうぞ よ っ て くださ い 。\n",
      "2019-11-26 10:52:45.771193 ... Target  = please look in on me when you 're in town .\n",
      "2019-11-26 10:52:45.771614 ... Predict = answer sob sob regretful regretful answer towel seemed seemed seemed towel towel  \n",
      "2019-11-26 10:52:45.772313 ... Epoch 1/10, Sample 48\n",
      "2019-11-26 10:52:45.772756 ... Source  = 彼女 は 大学 を 出 た ばかり の 英語 の 先生 だ 。\n",
      "2019-11-26 10:52:45.773243 ... Target  = she is an english teacher fresh from college .\n",
      "2019-11-26 10:52:45.773823 ... Predict = answer answer answer answer pendant pendant pendant enables enables enables    \n",
      "2019-11-26 10:52:45.774635 ... Epoch 1/10, Sample 49\n",
      "2019-11-26 10:52:45.779223 ... Source  = 日本 経済 は 今後 どう な る の だ ろ う か 。\n",
      "2019-11-26 10:52:45.779675 ... Target  = what will happen to the japanese economy ?\n",
      "2019-11-26 10:52:45.780113 ... Predict = dear prior dear dear prior frantically frantically frantically frantically     \n",
      "2019-11-26 10:52:45.780741 ... Epoch 1/10, Sample 50\n",
      "2019-11-26 10:52:45.785557 ... Source  = 仕事 を 済ま せ て から そちら へ 行 き ま す 。\n",
      "2019-11-26 10:52:45.786336 ... Target  = i 'll come over after i finish the work .\n",
      "2019-11-26 10:52:45.786996 ... Predict = answer answer answer answer answer 70,000 70,000 70,000 towel towel towel   \n",
      "2019-11-26 10:52:45.787779 ... Epoch 1/10, Sample 51\n",
      "2019-11-26 10:52:45.791029 ... Source  = 彼 は ３ 年間 神戸 に 住 ん で い ま す 。\n",
      "2019-11-26 10:52:45.791622 ... Target  = he has lived in kobe for three years .\n",
      "2019-11-26 10:52:45.792149 ... Predict = answer answer answer answer answer seemed seemed defended defended defended    \n",
      "2019-11-26 10:52:45.792861 ... Epoch 1/10, Sample 52\n",
      "2019-11-26 10:52:45.793354 ... Source  = だ から もう ここ に 着 い て い る はず だ 。\n",
      "2019-11-26 10:52:45.793878 ... Target  = so they ought to have arrived here by now .\n",
      "2019-11-26 10:52:45.794417 ... Predict = answer answer answer answer answer answer answer parentage parentage parentage parentage   \n",
      "2019-11-26 10:52:45.795127 ... Epoch 1/10, Sample 53\n",
      "2019-11-26 10:52:45.795683 ... Source  = トム は 昨日 夕食 を 食べ ま せ ん で し た 。\n",
      "2019-11-26 10:52:45.796160 ... Target  = tom didn 't have dinner last night .\n",
      "2019-11-26 10:52:45.796566 ... Predict = answer answer round prior 70,000 removed removed seemed removed     \n",
      "2019-11-26 10:52:45.797260 ... Epoch 1/10, Sample 54\n",
      "2019-11-26 10:52:45.797773 ... Source  = あの 子 は 一体 どう な っ て しま う の かしら 。\n",
      "2019-11-26 10:52:45.798252 ... Target  = i wonder what ever will become of the child .\n",
      "2019-11-26 10:52:45.798730 ... Predict = answer answer answer parentage parentage parentage parentage parentage parentage parentage parentage   \n",
      "2019-11-26 10:52:45.799403 ... Epoch 1/10, Sample 55\n",
      "2019-11-26 10:52:45.799902 ... Source  = どう し て 、 こんな に 暑 い の で す か 。\n",
      "2019-11-26 10:52:45.800386 ... Target  = why is it so hot ?\n",
      "2019-11-26 10:52:45.801666 ... Predict = answer answer answer answer answer answer answer       \n",
      "2019-11-26 10:52:45.802452 ... Epoch 1/10, Sample 56\n",
      "2019-11-26 10:52:45.802906 ... Source  = で も 、 そんな に 悪 く は な かっ た よ 。\n",
      "2019-11-26 10:52:45.803440 ... Target  = well , it wasn 't all that bad .\n",
      "2019-11-26 10:52:45.803932 ... Predict = answer answer answer answer answer answer answer answer answer answer    \n",
      "2019-11-26 10:52:45.804713 ... Epoch 1/10, Sample 57\n",
      "2019-11-26 10:52:45.805142 ... Source  = 私 と 彼 が その 計画 で 意見 が 一致 し た 。\n",
      "2019-11-26 10:52:45.805566 ... Target  = i agreed with him on the plan .\n",
      "2019-11-26 10:52:45.805991 ... Predict = died answer died died weep towel towel flown towel     \n",
      "2019-11-26 10:52:45.806611 ... Epoch 1/10, Sample 58\n",
      "2019-11-26 10:52:45.808015 ... Source  = 私 達 は 他 の 国 で は みんな 外国 人 だ 。\n",
      "2019-11-26 10:52:45.808468 ... Target  = we are all foreigners in other countries .\n",
      "2019-11-26 10:52:45.808889 ... Predict = answer answer flown bright swallow july july july july     \n",
      "2019-11-26 10:52:45.809512 ... Epoch 1/10, Sample 59\n",
      "2019-11-26 10:52:45.809934 ... Source  = あなた の 時計 、 時間 は 狂 い ま せ ん か 。\n",
      "2019-11-26 10:52:45.810670 ... Target  = does your watch keep good time ?\n",
      "2019-11-26 10:52:45.811228 ... Predict = answer answer evident prior prior evident prior prior      \n",
      "2019-11-26 10:52:45.811903 ... Epoch 1/10, Sample 60\n",
      "2019-11-26 10:52:45.820824 ... Source  = 午後 は 午前 中 に 勉強 する よう に し よ う 。\n",
      "2019-11-26 10:52:45.821273 ... Target  = from now on let us study in the morning .\n",
      "2019-11-26 10:52:45.821779 ... Predict = answer a pendant pendant bedtime pendant pendant pendant pendant pendant pendant   \n",
      "2019-11-26 10:52:45.822546 ... Epoch 1/10, Sample 61\n",
      "2019-11-26 10:52:45.824103 ... Source  = お 兄 さん が 結婚 なさ っ た の で す ね 。\n",
      "2019-11-26 10:52:45.824524 ... Target  = your brother got married , didn 't he ?\n",
      "2019-11-26 10:52:45.824946 ... Predict = debate debate debate debate pendant seemed seemed seemed answer seemed    \n",
      "2019-11-26 10:52:45.826372 ... Epoch 1/10, Sample 62\n",
      "2019-11-26 10:52:45.827405 ... Source  = 彼 は 正直 な の で 多く の 友人 が い る 。\n",
      "2019-11-26 10:52:45.827973 ... Target  = he gains many friends through his honesty .\n",
      "2019-11-26 10:52:45.828366 ... Predict = answer answer answer answer answer answer answer answer answer     \n",
      "2019-11-26 10:52:45.828983 ... Epoch 1/10, Sample 63\n",
      "2019-11-26 10:52:45.829400 ... Source  = 私 は 彼 に 時計 を 修理 し て もら っ た 。\n",
      "2019-11-26 10:52:45.829808 ... Target  = i had him mend my watch .\n",
      "2019-11-26 10:52:45.831271 ... Predict = merchant answer answer grappled towel towel towel towel      \n",
      "2019-11-26 10:52:45.832198 ... Epoch 1/10, Sample 64\n",
      "2019-11-26 10:52:45.832762 ... Source  = 私 の 言 っ た こと を 絶対 の 忘れ る な 。\n",
      "2019-11-26 10:52:45.833180 ... Target  = don 't forget what i told you .\n",
      "2019-11-26 10:52:45.833627 ... Predict = europe consists protested protested 70,000 70,000 protested prison towel     \n",
      "2019-11-26 10:52:45.834342 ... Epoch 1/10, Sample 65\n",
      "2019-11-26 10:52:45.834752 ... Source  = 彼女 は 子供 の 栄養 に 気 を つけ て い る 。\n",
      "2019-11-26 10:52:45.835167 ... Target  = she is careful about her child 's nutrition .\n",
      "2019-11-26 10:52:45.835620 ... Predict = answer answer answer answer prior answer pendant grappled grappled grappled    \n",
      "2019-11-26 10:52:45.836498 ... Epoch 1/10, Sample 66\n",
      "2019-11-26 10:52:45.836926 ... Source  = 彼 に は 子供 が せいぜい ３ 人 ぐらい しか な い 。\n",
      "2019-11-26 10:52:45.837427 ... Target  = he has not more than three children .\n",
      "2019-11-26 10:52:45.837814 ... Predict = answer answer answer answer answer jogging $ $ $     \n",
      "2019-11-26 10:52:45.838453 ... Epoch 1/10, Sample 67\n",
      "2019-11-26 10:52:45.838911 ... Source  = 彼 は この 間 彼女 に 会 い に 行 っ た 。\n",
      "2019-11-26 10:52:45.844380 ... Target  = he went to see her the other day .\n",
      "2019-11-26 10:52:45.844800 ... Predict = answer answer answer answer grappled grappled answer paradise paradise paradise    \n",
      "2019-11-26 10:52:45.845493 ... Epoch 1/10, Sample 68\n",
      "2019-11-26 10:52:45.846010 ... Source  = ご 主人 は 本日 お 見え に な る で しょ う 。\n",
      "2019-11-26 10:52:45.846475 ... Target  = i believe he 'll be with us today .\n",
      "2019-11-26 10:52:45.846963 ... Predict = answer answer answer answer answer answer frantically frantically frantically towel    \n",
      "2019-11-26 10:52:45.847625 ... Epoch 1/10, Sample 69\n",
      "2019-11-26 10:52:45.850263 ... Source  = それ じゃあ 元 も 子 も な い じゃ な い か 。\n",
      "2019-11-26 10:52:45.856032 ... Target  = then that means i lost everything .\n",
      "2019-11-26 10:52:45.858049 ... Predict = prior prior prior prior prior prior prior prior      \n",
      "2019-11-26 10:52:45.858973 ... Epoch 1/10, Sample 70\n",
      "2019-11-26 10:52:45.859695 ... Source  = パリ に 滞在 中 、 私 は 彼 に あ っ た 。\n",
      "2019-11-26 10:52:45.860259 ... Target  = while i was staying in paris , i met him .\n",
      "2019-11-26 10:52:45.860819 ... Predict = answer answer answer answer answer answer answer grappled answer answer towel towel  \n",
      "2019-11-26 10:52:45.861612 ... Epoch 1/10, Sample 71\n",
      "2019-11-26 10:52:45.862148 ... Source  = 彼 は 授業 中 いつ も 居眠り ばかり し て い る 。\n",
      "2019-11-26 10:52:45.862844 ... Target  = he is always taking a nap at school .\n",
      "2019-11-26 10:52:45.863273 ... Predict = answer answer answer answer answer answer answer seemed answer answer    \n",
      "2019-11-26 10:52:45.864160 ... Epoch 1/10, Sample 72\n",
      "2019-11-26 10:52:45.864809 ... Source  = 彼女 へ の プレゼント を 家 に 置 い て き た 。\n",
      "2019-11-26 10:52:45.865393 ... Target  = i had left a present for her at my house .\n",
      "2019-11-26 10:52:45.866033 ... Predict = answer answer answer answer answer answer grappled grappled seemed seemed seemed seemed  \n",
      "2019-11-26 10:52:45.866825 ... Epoch 1/10, Sample 73\n",
      "2019-11-26 10:52:45.867562 ... Source  = 君 の 考え など は どう だ って い い こと だ 。\n",
      "2019-11-26 10:52:45.868479 ... Target  = your thoughts are of no significance at all .\n",
      "2019-11-26 10:52:45.869126 ... Predict = answer acted acted duck frantically frantically frantically frantically parentage parentage    \n",
      "2019-11-26 10:52:45.869957 ... Epoch 1/10, Sample 74\n",
      "2019-11-26 10:52:45.871617 ... Source  = 彼女 は ロンドン か パリ の どちら か に 行 っ た 。\n",
      "2019-11-26 10:52:45.872462 ... Target  = she went either to london or to paris .\n",
      "2019-11-26 10:52:45.873031 ... Predict = answer answer answer answer answer answer answer evident evident answer    \n",
      "2019-11-26 10:52:45.873816 ... Epoch 1/10, Sample 75\n",
      "2019-11-26 10:52:45.874334 ... Source  = 私 達 は 近く の 公園 で キャッチ ボール を し た 。\n",
      "2019-11-26 10:52:45.874858 ... Target  = we played catch in a park near by .\n",
      "2019-11-26 10:52:45.876431 ... Predict = answer answer answer answer july pendant july pendant enables enables    \n",
      "2019-11-26 10:52:45.877230 ... Epoch 1/10, Sample 76\n",
      "2019-11-26 10:52:45.877743 ... Source  = 母 だけ が 本当 に 私 を 理解 し て い る 。\n",
      "2019-11-26 10:52:45.878152 ... Target  = only my mother really understands me .\n",
      "2019-11-26 10:52:45.878664 ... Predict = died died browns browns browns seemed seemed seemed      \n",
      "2019-11-26 10:52:45.879320 ... Epoch 1/10, Sample 77\n",
      "2019-11-26 10:52:45.879824 ... Source  = 彼 は 甘 い もの なら なん で も 好き で す 。\n",
      "2019-11-26 10:52:45.884453 ... Target  = he likes anything sweet .\n",
      "2019-11-26 10:52:45.891415 ... Predict = answer answer answer answer answer answer        \n",
      "2019-11-26 10:52:45.892150 ... Epoch 1/10, Sample 78\n",
      "2019-11-26 10:52:45.894086 ... Source  = 彼女 を 愛 さ ず に は い られ な い なあ 。\n",
      "2019-11-26 10:52:45.894600 ... Target  = i cannot help falling in love with her .\n",
      "2019-11-26 10:52:45.895111 ... Predict = answer answer answer prior prior prior prior prior answer answer    \n",
      "2019-11-26 10:52:45.895849 ... Epoch 1/10, Sample 79\n",
      "2019-11-26 10:52:45.896708 ... Source  = 私 は 彼女 に 部屋 を 掃除 し て もら っ た 。\n",
      "2019-11-26 10:52:45.897258 ... Target  = i got her to clean my room .\n",
      "2019-11-26 10:52:45.897766 ... Predict = merchant answer answer answer towel towel towel towel towel     \n",
      "2019-11-26 10:52:45.898510 ... Epoch 1/10, Sample 80\n",
      "2019-11-26 10:52:45.899037 ... Source  = 彼 ら は 明日 飛行 機 で 行 っ て しま う 。\n",
      "2019-11-26 10:52:45.899564 ... Target  = they are going off by plane tomorrow .\n",
      "2019-11-26 10:52:45.900077 ... Predict = answer answer answer answer expelled expelled expelled expelled expelled     \n",
      "2019-11-26 10:52:45.905005 ... Epoch 1/10, Sample 81\n",
      "2019-11-26 10:52:45.905973 ... Source  = テレビ を 見 ながら 新聞 を 読 む 人 も い る 。\n",
      "2019-11-26 10:52:45.906692 ... Target  = some people read the newspaper while watching television .\n",
      "2019-11-26 10:52:45.907142 ... Predict = happy happy vehicles remarkable remarkable remarkable remarkable remarkable remarkable answer    \n",
      "2019-11-26 10:52:45.908549 ... Epoch 1/10, Sample 82\n",
      "2019-11-26 10:52:45.910155 ... Source  = その 本 が 欲し い 人 は だれ で も もらえ る 。\n",
      "2019-11-26 10:52:45.910631 ... Target  = whoever wants the book may have it .\n",
      "2019-11-26 10:52:45.911176 ... Predict = answer answer answer answer answer prior jogging jogging answer     \n",
      "2019-11-26 10:52:45.912248 ... Epoch 1/10, Sample 83\n",
      "2019-11-26 10:52:45.912881 ... Source  = これ ら の 問題 は 私 に と っ て 重要 だ 。\n",
      "2019-11-26 10:52:45.913397 ... Target  = these problems are important to me .\n",
      "2019-11-26 10:52:45.914613 ... Predict = answer vehicles parentage protested parentage parentage parentage parentage      \n",
      "2019-11-26 10:52:45.915691 ... Epoch 1/10, Sample 84\n",
      "2019-11-26 10:52:45.916255 ... Source  = 私 の 代わり に い っ て くれ ま せ ん か 。\n",
      "2019-11-26 10:52:45.916654 ... Target  = will you go in place of me ?\n",
      "2019-11-26 10:52:45.917115 ... Predict = answer protested prior prior prior prior prior evident removed     \n",
      "2019-11-26 10:52:45.917938 ... Epoch 1/10, Sample 85\n",
      "2019-11-26 10:52:45.918437 ... Source  = 誰 も 私 の 手伝い を し て くれ な かっ た 。\n",
      "2019-11-26 10:52:45.918879 ... Target  = no one helped me .\n",
      "2019-11-26 10:52:45.919400 ... Predict = prior prior prior prior prior prior        \n",
      "2019-11-26 10:52:45.920041 ... Epoch 1/10, Sample 86\n",
      "2019-11-26 10:52:45.920527 ... Source  = 私 は その ものすご く 大きな 魚 に 大変 驚 い た 。\n",
      "2019-11-26 10:52:45.920963 ... Target  = i was very surprised at the huge fish .\n",
      "2019-11-26 10:52:45.921361 ... Predict = answer answer answer answer answer answer answer answer pendant towel    \n",
      "2019-11-26 10:52:45.922016 ... Epoch 1/10, Sample 87\n",
      "2019-11-26 10:52:45.927645 ... Source  = 写真 家 が 私 の 家 の 写真 を 取 っ た 。\n",
      "2019-11-26 10:52:45.928144 ... Target  = a photographer took a photograph of my house .\n",
      "2019-11-26 10:52:45.928595 ... Predict = answer answer debate spots browns seemed seemed seemed seemed seemed    \n",
      "2019-11-26 10:52:45.929291 ... Epoch 1/10, Sample 88\n",
      "2019-11-26 10:52:45.929749 ... Source  = 昨日 学校 を 休 ん だ 理由 を い い なさ い 。\n",
      "2019-11-26 10:52:45.930228 ... Target  = tell me the reason for your absence from school yesterday .\n",
      "2019-11-26 10:52:45.930655 ... Predict = answer answer answer answer answer nimble nimble nimble prior answer answer answer  \n",
      "2019-11-26 10:52:45.931366 ... Epoch 1/10, Sample 89\n",
      "2019-11-26 10:52:45.931974 ... Source  = どう 埋め合わせ し たら 良 い か わか り ま せ ん 。\n",
      "2019-11-26 10:52:45.932406 ... Target  = there 's no way i can make it up to you .\n",
      "2019-11-26 10:52:45.935098 ... Predict = answer answer answer prior prior prior removed prior removed removed nimble removed removed \n",
      "2019-11-26 10:52:45.937001 ... Epoch 1/10, Sample 90\n",
      "2019-11-26 10:52:45.937543 ... Source  = 忘れ ず に 雨具 を も っ て き て くださ い 。\n",
      "2019-11-26 10:52:45.938574 ... Target  = be sure to bring rain gear .\n",
      "2019-11-26 10:52:45.939115 ... Predict = answer answer answer merchant merchant parentage merchant merchant      \n",
      "2019-11-26 10:52:45.939850 ... Epoch 1/10, Sample 91\n",
      "2019-11-26 10:52:45.940431 ... Source  = その 店 は いつ まで 開 い て い ま す か 。\n",
      "2019-11-26 10:52:45.940873 ... Target  = when is the store open till ?\n",
      "2019-11-26 10:52:45.943655 ... Predict = answer answer answer answer evident evident evident evident      \n",
      "2019-11-26 10:52:45.944306 ... Epoch 1/10, Sample 92\n",
      "2019-11-26 10:52:45.944811 ... Source  = 彼 は どちら か と 言 え ば 背 が 高 い 。\n",
      "2019-11-26 10:52:45.946339 ... Target  = he is , if anything , tall .\n",
      "2019-11-26 10:52:45.946831 ... Predict = answer answer answer answer answer lest lest answer answer     \n",
      "2019-11-26 10:52:45.948164 ... Epoch 1/10, Sample 93\n",
      "2019-11-26 10:52:45.949104 ... Source  = 彼 は 外国 で ２ 年間 研究 する 特典 を 得 た 。\n",
      "2019-11-26 10:52:45.949612 ... Target  = he had the privilege of studying abroad for two years .\n",
      "2019-11-26 10:52:45.950076 ... Predict = answer answer answer answer answer pendant pendant enables enables enables enables enables  \n",
      "2019-11-26 10:52:45.950706 ... Epoch 1/10, Sample 94\n",
      "2019-11-26 10:52:45.952423 ... Source  = 長 い 間 待た し て 申し訳 あ り ま せ ん 。\n",
      "2019-11-26 10:52:45.952863 ... Target  = i 'm sorry i 've kept you waiting so long .\n",
      "2019-11-26 10:52:45.953425 ... Predict = answer answer answer answer answer removed nimble removed removed removed removed removed  \n",
      "2019-11-26 10:52:45.954114 ... Epoch 1/10, Sample 95\n",
      "2019-11-26 10:52:45.954605 ... Source  = 次 に 何 を し たら よ い の で す か 。\n",
      "2019-11-26 10:52:45.955042 ... Target  = what am i to do next ?\n",
      "2019-11-26 10:52:45.955520 ... Predict = answer answer answer answer answer evident evident evident      \n",
      "2019-11-26 10:52:45.956180 ... Epoch 1/10, Sample 96\n",
      "2019-11-26 10:52:45.956663 ... Source  = 彼 は 空港 に 友人 を 見送り に 出かけ ま し た 。\n",
      "2019-11-26 10:52:45.957102 ... Target  = he went to the airport to see his friend off .\n",
      "2019-11-26 10:52:45.957515 ... Predict = answer answer answer pendant pendant pendant pendant pendant pendant pendant towel towel  \n",
      "2019-11-26 10:52:45.961926 ... Epoch 1/10, Sample 97\n",
      "2019-11-26 10:52:45.962413 ... Source  = 母 は 父 に ケーキ を 作 っ て い ま す 。\n",
      "2019-11-26 10:52:45.963085 ... Target  = my mother is making my father a cake .\n",
      "2019-11-26 10:52:45.963546 ... Predict = answer answer answer answer seemed seemed seemed seemed seemed seemed    \n",
      "2019-11-26 10:52:45.964997 ... Epoch 1/10, Sample 98\n",
      "2019-11-26 10:52:45.967229 ... Source  = もし 万一 彼 が 失敗 すれ ば どう な る の か 。\n",
      "2019-11-26 10:52:45.968713 ... Target  = what if he should fail ?\n",
      "2019-11-26 10:52:45.969186 ... Predict = answer prior prior prior prior prior prior       \n",
      "2019-11-26 10:52:45.971082 ... Epoch 1/10, Sample 99\n",
      "2019-11-26 10:52:45.971629 ... Source  = それ は 時間 の 問題 と みな さ れ て い る 。\n",
      "2019-11-26 10:52:45.972103 ... Target  = it is regarded as a matter of time .\n",
      "2019-11-26 10:52:45.973124 ... Predict = sob sob answer sob answer quieter seemed prior parentage parentage    \n",
      "2019-11-26 10:52:45.973971 ... Epoch 1/10, Sample 100\n",
      "2019-11-26 10:52:45.974417 ... Source  = あれ は 私 の ペン で は あ り ま せ ん 。\n",
      "2019-11-26 10:52:45.975018 ... Target  = that is not my pen .\n",
      "2019-11-26 10:52:45.975439 ... Predict = answer answer answer round seemed seemed tani       \n",
      "2019-11-26 10:52:45.978305 ... Epoch 1/10, Sample 101\n",
      "2019-11-26 10:52:45.978756 ... Source  = ケン は 家 に 帰 る 途中 彼女 に 会 っ た 。\n",
      "2019-11-26 10:52:45.979347 ... Target  = ken met her on his way home .\n",
      "2019-11-26 10:52:45.979783 ... Predict = answer answer answer browns browns browns browns browns browns     \n",
      "2019-11-26 10:52:45.980544 ... Epoch 1/10, Sample 102\n",
      "2019-11-26 10:52:45.980992 ... Source  = 私 達 は ６ 年間 大阪 に 住 ん で い た 。\n",
      "2019-11-26 10:52:45.981479 ... Target  = we have lived in osaka six years .\n",
      "2019-11-26 10:52:45.981901 ... Predict = answer answer answer answer answer answer answer answer answer     \n",
      "2019-11-26 10:52:45.982633 ... Epoch 1/10, Sample 103\n",
      "2019-11-26 10:52:45.986467 ... Source  = 懐かし い 昔 の こと を 話 す の が 好き だ 。\n",
      "2019-11-26 10:52:45.987003 ... Target  = i like to talk about the good old days .\n",
      "2019-11-26 10:52:45.987482 ... Predict = cracking cracking cracking jogging frantically frantically frantically bait bait bait parentage   \n",
      "2019-11-26 10:52:45.988357 ... Epoch 1/10, Sample 104\n",
      "2019-11-26 10:52:45.988843 ... Source  = 彼 ら は 生き て い く の が やっと だっ た 。\n",
      "2019-11-26 10:52:45.989544 ... Target  = they could barely make ends meet .\n",
      "2019-11-26 10:52:45.989983 ... Predict = answer answer answer answer answer answer answer answer      \n",
      "2019-11-26 10:52:45.990714 ... Epoch 1/10, Sample 105\n",
      "2019-11-26 10:52:45.991132 ... Source  = その 話 は 本当 に 様 に は 聞こえ な かっ た 。\n",
      "2019-11-26 10:52:45.993016 ... Target  = the story didn 't sound true .\n",
      "2019-11-26 10:52:45.993796 ... Predict = answer answer answer protested protested protested protested protested      \n",
      "2019-11-26 10:52:45.994455 ... Epoch 1/10, Sample 106\n",
      "2019-11-26 10:52:45.995213 ... Source  = 彼女 から の 返事 は 納得 でき な い もの だっ た 。\n",
      "2019-11-26 10:52:45.995704 ... Target  = her answer couldn 't be understood .\n",
      "2019-11-26 10:52:45.996214 ... Predict = answer answer answer answer answer answer answer answer      \n",
      "2019-11-26 10:52:45.996973 ... Epoch 1/10, Sample 107\n",
      "2019-11-26 10:52:45.997581 ... Source  = 彼 は 一生 懸命 や っ た が 、 失敗 し た 。\n",
      "2019-11-26 10:52:45.998053 ... Target  = he tried hard , but he failed .\n",
      "2019-11-26 10:52:45.998543 ... Predict = answer answer answer answer answer browns answer pendant pendant     \n",
      "2019-11-26 10:52:45.999236 ... Epoch 1/10, Sample 108\n",
      "2019-11-26 10:52:45.999960 ... Source  = この カメラ は 、 おじが 私 に くれ た もの で す 。\n",
      "2019-11-26 10:52:46.000396 ... Target  = this camera was given me by my uncle .\n",
      "2019-11-26 10:52:46.005820 ... Predict = answer happy happy answer pendant spots enables enables enables enables    \n",
      "2019-11-26 10:52:46.006556 ... Epoch 1/10, Sample 109\n",
      "2019-11-26 10:52:46.007027 ... Source  = 君 は ここ に 座 って い さえ すれ ば い い 。\n",
      "2019-11-26 10:52:46.007616 ... Target  = you have only to sit here .\n",
      "2019-11-26 10:52:46.008067 ... Predict = answer answer answer answer answer answer answer answer      \n",
      "2019-11-26 10:52:46.009032 ... Epoch 1/10, Sample 110\n",
      "2019-11-26 10:52:46.009667 ... Source  = 彼女 は 親 の 言 う 事 を 良 く 聞 く 。\n",
      "2019-11-26 10:52:46.010094 ... Target  = she is obedient to her parents .\n",
      "2019-11-26 10:52:46.010627 ... Predict = now answer answer answer pendant now pendant dine      \n",
      "2019-11-26 10:52:46.011263 ... Epoch 1/10, Sample 111\n",
      "2019-11-26 10:52:46.011791 ... Source  = 私 は 彼女 が 部屋 に 入 る の を 見 た 。\n",
      "2019-11-26 10:52:46.012241 ... Target  = i saw her enter the room .\n",
      "2019-11-26 10:52:46.012739 ... Predict = answer answer answer answer answer towel browns browns      \n",
      "2019-11-26 10:52:46.013362 ... Epoch 1/10, Sample 112\n",
      "2019-11-26 10:52:46.013865 ... Source  = あなた は 彼 が 誰 だ と 思 い ま す か 。\n",
      "2019-11-26 10:52:46.014292 ... Target  = who do you think he is ?\n",
      "2019-11-26 10:52:46.014727 ... Predict = dear acted prior prior prior prior prior prior      \n",
      "2019-11-26 10:52:46.015359 ... Epoch 1/10, Sample 113\n",
      "2019-11-26 10:52:46.015958 ... Source  = もし 事故 が 起き たら 、 私 に 報告 し なさ い 。\n",
      "2019-11-26 10:52:46.016373 ... Target  = if the accident happens , report to me .\n",
      "2019-11-26 10:52:46.016867 ... Predict = answer merchant answer answer answer answer answer answer answer towel    \n",
      "2019-11-26 10:52:46.017519 ... Epoch 1/10, Sample 114\n",
      "2019-11-26 10:52:46.018053 ... Source  = そんな こと を し たら 罰 せ られ る だ ろ う 。\n",
      "2019-11-26 10:52:46.018486 ... Target  = were we to do such a thing , we should be punished .\n",
      "2019-11-26 10:52:46.018985 ... Predict = consists demand prior prior prior prior expectations half-hours expectations removed removed removed removed parentage\n",
      "2019-11-26 10:52:46.019614 ... Epoch 1/10, Sample 115\n",
      "2019-11-26 10:52:46.020140 ... Source  = スポーツ が 好き な の は 、 父親 譲り な ん だ 。\n",
      "2019-11-26 10:52:46.020582 ... Target  = i love sports . i get that from my father .\n",
      "2019-11-26 10:52:46.021075 ... Predict = answer answer answer frantically frantically answer frantically frantically frantically frantically frantically frantically  \n",
      "2019-11-26 10:52:46.021714 ... Epoch 1/10, Sample 116\n",
      "2019-11-26 10:52:46.022232 ... Source  = ビル は どう も メアリー に 惚れ て い る ら しい 。\n",
      "2019-11-26 10:52:46.022667 ... Target  = bill seems to be stuck on mary .\n",
      "2019-11-26 10:52:46.023114 ... Predict = answer answer answer prior prior prior prior prior prior     \n",
      "2019-11-26 10:52:46.023776 ... Epoch 1/10, Sample 117\n",
      "2019-11-26 10:52:46.024305 ... Source  = 彼 ら も 来 て も かま い ま せ ん か 。\n",
      "2019-11-26 10:52:46.024746 ... Target  = do you mind their coming too ?\n",
      "2019-11-26 10:52:46.025231 ... Predict = prior prior prior prior prior prior prior prior      \n",
      "2019-11-26 10:52:46.025923 ... Epoch 1/10, Sample 118\n",
      "2019-11-26 10:52:46.026437 ... Source  = 彼 が そこ へ 行 っ た の は 明らか だっ た 。\n",
      "2019-11-26 10:52:46.029444 ... Target  = it was clear that he went there .\n",
      "2019-11-26 10:52:46.030168 ... Predict = answer answer answer answer answer answer answer dream answer     \n",
      "2019-11-26 10:52:46.031725 ... Epoch 1/10, Sample 119\n",
      "2019-11-26 10:52:46.032429 ... Source  = 以前 、 彼女 に 会 っ た よう な 気 が する 。\n",
      "2019-11-26 10:52:46.032964 ... Target  = it feels like i 've seen her before .\n",
      "2019-11-26 10:52:46.033447 ... Predict = answer answer answer answer answer answer answer answer answer towel    \n",
      "2019-11-26 10:52:46.034114 ... Epoch 1/10, Sample 120\n",
      "2019-11-26 10:52:46.034869 ... Source  = 外国 語 を マスター する に は 何 年 も かか る 。\n",
      "2019-11-26 10:52:46.035290 ... Target  = it takes years to master a foreign language .\n",
      "2019-11-26 10:52:46.035734 ... Predict = answer answer answer answer pendant pendant pendant seemed seemed enables    \n",
      "2019-11-26 10:52:46.036356 ... Epoch 1/10, Sample 121\n",
      "2019-11-26 10:52:46.037042 ... Source  = 彼女 は その 秘密 を 知 っ て い た よう だ 。\n",
      "2019-11-26 10:52:46.037466 ... Target  = she seems to have known the secret .\n",
      "2019-11-26 10:52:46.037979 ... Predict = answer answer answer answer parentage parentage parentage parentage parentage     \n",
      "2019-11-26 10:52:46.038599 ... Epoch 1/10, Sample 122\n",
      "2019-11-26 10:52:46.039337 ... Source  = お前 に と っ て は どう で も い い こと 。\n",
      "2019-11-26 10:52:46.047146 ... Target  = i know you don 't care .\n",
      "2019-11-26 10:52:46.052283 ... Predict = answer answer answer answer evident answer answer answer      \n",
      "2019-11-26 10:52:46.052994 ... Epoch 1/10, Sample 123\n",
      "2019-11-26 10:52:46.054100 ... Source  = ここ に もう 少し い る こと が でき ま す か 。\n",
      "2019-11-26 10:52:46.055691 ... Target  = is it possible to be here a little longer ?\n",
      "2019-11-26 10:52:46.056757 ... Predict = answer answer evident evident evident evident evident evident evident evident evident   \n",
      "2019-11-26 10:52:46.057556 ... Epoch 1/10, Sample 124\n",
      "2019-11-26 10:52:46.058106 ... Source  = 彼 は 決して 貧し い 人 たち を 軽蔑 し な い 。\n",
      "2019-11-26 10:52:46.058599 ... Target  = he never looks down on poor people .\n",
      "2019-11-26 10:52:46.059134 ... Predict = answer answer answer answer answer answer answer answer answer     \n",
      "2019-11-26 10:52:46.059955 ... Epoch 1/10, Sample 125\n",
      "2019-11-26 10:52:46.060557 ... Source  = ひど い 風邪 で あの 娘 は 授業 を 休 ん だ 。\n",
      "2019-11-26 10:52:46.061077 ... Target  = a bad cold prevented her from attending the class .\n",
      "2019-11-26 10:52:46.064371 ... Predict = answer answer answer answer prior quieter quieter up-to-date quieter quieter answer   \n",
      "2019-11-26 10:52:46.065134 ... Epoch 1/10, Sample 126\n",
      "2019-11-26 10:52:46.065626 ... Source  = 彼 は 良 い 忠告 を 一 つ し て くれ た 。\n",
      "2019-11-26 10:52:46.066318 ... Target  = he gave a good piece of advice .\n",
      "2019-11-26 10:52:46.066797 ... Predict = sob answer answer answer seemed seemed seemed seemed seemed     \n",
      "2019-11-26 10:52:46.068161 ... Epoch 1/10, Sample 127\n",
      "2019-11-26 10:52:46.068749 ... Source  = 彼 ばかり で な く 私 も まちが っ て い る 。\n",
      "2019-11-26 10:52:46.069166 ... Target  = not only he but i am wrong .\n",
      "2019-11-26 10:52:46.070077 ... Predict = answer answer answer answer answer answer answer answer answer     \n",
      "2019-11-26 10:52:46.070693 ... Epoch 1/10, Sample 128\n",
      "2019-11-26 10:52:46.072011 ... Source  = 私 は 彼 ら に 馬鹿 に さ れ て い た 。\n",
      "2019-11-26 10:52:46.072551 ... Target  = i was being made a fool of .\n",
      "2019-11-26 10:52:46.072964 ... Predict = sob answer answer answer answer grappled grappled grappled grappled     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-816a2c5d61f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfiguration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start Testing ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-29f71cede998>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0maccum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, retain_grad, enable_double_backprop, loss_scale)\u001b[0m\n\u001b[1;32m    961\u001b[0m         \"\"\"\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musing_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enable_backprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_double_backprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_backward_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/variable.py\u001b[0m in \u001b[0;36m_backward_main\u001b[0;34m(self, retain_grad, loss_scale)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             gxs = func.backward_accumulate(\n\u001b[0;32m-> 1092\u001b[0;31m                 target_input_indexes, out_grad, in_grad)\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgxs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mbackward_accumulate\u001b[0;34m(self, target_input_indexes, grad_outputs, grad_inputs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;31m# The default implementation uses backward(). You can override this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# method without using backward().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mgxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_input_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mlen_gxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/functions/connection/linear.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, indexes, grad_outputs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mgW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearGradWeight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/function_node.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_indexes_to_retain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_indexes_to_retain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# Check for output array types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/chainer/functions/connection/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mgy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mgW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_w_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sys.argv[1] = 'train'\n",
    "    sys.argv[2] = '/home/alireza/Downloads/GAN-NMT-master/jcode/sample/sample_gan.config'\n",
    "    config = Configuration(sys.argv[1], sys.argv[2])\n",
    "    if config.mode == \"train\":\n",
    "        train(config)\n",
    "    elif config.mode == \"test\":\n",
    "        trace(\"Start Testing ...\")\n",
    "        config.source_file = config.source_test\n",
    "        config.predict_file = \"{}.test_result.beam{}\".format(config.model, config.beam_size)\n",
    "        config.model = \"{}.{:03d}\".format(config.model, int(sys.argv[3]))\n",
    "        test(config)\n",
    "        trace(\"Finished.\")\n",
    "    elif config.mode == \"dev\":\n",
    "        trace(\"Start Developing ...\")\n",
    "        config.source_file = config.source_dev\n",
    "        model = config.model\n",
    "        if len(sys.argv) == 5:\n",
    "            start = int(sys.argv[3]) - 1\n",
    "            end = int(sys.argv[4])\n",
    "        else:\n",
    "            start = 0\n",
    "            end = config.epoch\n",
    "        for i in range(start, end):\n",
    "            config.model = \"{}.{:03d}\".format(model, i + 1)\n",
    "            trace(\"Model {}/{}\".format(i + 1, config.epoch))\n",
    "            config.predict_file = \"{}.dev_result\".format(config.model)\n",
    "            test(config)\n",
    "        trace(\"Finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"در ادامه نمونه از خروجی شبکه بر روی داده ای محدود از ترجمه زبان انگلیسی به ژاپنی را مشاهده می نماییم. خروجی زیر مربوط به زمانی است که قصد آموزش شبکه ماشین ترجمه عصبی را داشته ایم. خروجی حاصل مربوط به دور 3 اجرا و در بخش انتهایی از مرحله آموزش است.\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
